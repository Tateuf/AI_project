{
    "history": [
        {
            "date": "2022-12-25",
            "time": "11:47:15.047995",
            "file": "sample_0_1_c.png",
            "content": ""
        },
        {
            "date": "2022-12-26",
            "time": "15:15:29.299756",
            "file": "press_train_2_1_c.png",
            "content": "South China Morning\n\nYou can't blame the education system once you've reached university\nPUMURSEEL Mondiry 3 Avowit, 25\u00b0 82 ary\n\nBBDATED. kkwesny. 12 Ragpet 294 \u00ab2pm\n\nMtewite - Saerhee | HEPEC HONS\n\nLheae Yeung Bote.yeunpincae. come\n\nFamary atuaents hav to take cumeesing of thes iacneng and aint. the net\nwileosien caacteng and aniing Ihey are brought up 2\n\n# MG\n\nFe eeaney Saran! seccetncy\nVocigets, \u2018he Pade wim cng fetieg Gergen tae Pye wpa Eimy Reve fine imi at 162909!\nPapen ee Nessa io BEET Hee Maat eae\u2019N ny Kenny Drpkorta of Reconeary Soucatce,\nquate!\n\nTMi a2 Seki at CELE IGE GA Sat RRA Madness wt\" eM exam\nSyonal hoe werige meccoralary Sent Yo xen mnt Akad Matyng \u201ceee ee tm\n\ntae Baie fen ae et MOI rE ERY Rubee 8 SR ECRN Ae Hoos Hema fC PAE:\nagen rim END, MLC Seer Sy BEAKER Aaah, eR A Ac\nBORE Ot HRP OO uO ONION Le \u201cHAT SE Mabe NG A ET\nsen Mle\n\nSe meme chonenet, 16 Lae Ke Sa Cemhaeae: CE RI ka AR ARS Sa RRL\nnteaoe coca i Rg Une wee Cou ap om Thm ns 8 coal wR pe fe Ma Me\nSPOR eaaemnATOR hE Be Bed a kame NEPA I eH yh\n\naca, 3 DNC A exports There 206 oe Sant\nEy iseaeuek AP aeiee WP om rear ary gn SU Fee Rae ye Genre A Sey tag\ncam pacing Bol geting kip gracon \u00a9 aa autts Ocean nod aC Marae OG a tah COs\nef eer phinpthlity Oe eecrany Sawiboetey ee See Cage ead Tse sega BITE\n\nim coy tas maior) os\n\nrenee nte siaty seman Rha 89\n\n"
        },
        {
            "date": "2022-12-26",
            "time": "15:15:30.473093",
            "file": "press_train_2_1_c.png",
            "content": "South China Morning\n\nYou can't blame the education system once you've reached university\nPUMURSEEL Mondiry 3 Avowit, 25\u00b0 82 ary\n\nBBDATED. kkwesny. 12 Ragpet 294 \u00ab2pm\n\nMtewite - Saerhee | HEPEC HONS\n\nLheae Yeung Bote.yeunpincae. come\n\nFamary atuaents hav to take cumeesing of thes iacneng and aint. the net\nwileosien caacteng and aniing Ihey are brought up 2\n\n# MG\n\nFe eeaney Saran! seccetncy\nVocigets, \u2018he Pade wim cng fetieg Gergen tae Pye wpa Eimy Reve fine imi at 162909!\nPapen ee Nessa io BEET Hee Maat eae\u2019N ny Kenny Drpkorta of Reconeary Soucatce,\nquate!\n\nTMi a2 Seki at CELE IGE GA Sat RRA Madness wt\" eM exam\nSyonal hoe werige meccoralary Sent Yo xen mnt Akad Matyng \u201ceee ee tm\n\ntae Baie fen ae et MOI rE ERY Rubee 8 SR ECRN Ae Hoos Hema fC PAE:\nagen rim END, MLC Seer Sy BEAKER Aaah, eR A Ac\nBORE Ot HRP OO uO ONION Le \u201cHAT SE Mabe NG A ET\nsen Mle\n\nSe meme chonenet, 16 Lae Ke Sa Cemhaeae: CE RI ka AR ARS Sa RRL\nnteaoe coca i Rg Une wee Cou ap om Thm ns 8 coal wR pe fe Ma Me\nSPOR eaaemnATOR hE Be Bed a kame NEPA I eH yh\n\naca, 3 DNC A exports There 206 oe Sant\nEy iseaeuek AP aeiee WP om rear ary gn SU Fee Rae ye Genre A Sey tag\ncam pacing Bol geting kip gracon \u00a9 aa autts Ocean nod aC Marae OG a tah COs\nef eer phinpthlity Oe eecrany Sawiboetey ee See Cage ead Tse sega BITE\n\nim coy tas maior) os\n\nrenee nte siaty seman Rha 89\n\n"
        },
        {
            "date": "2022-12-26",
            "time": "15:18:55.460593",
            "file": "press_2_1672064334497.png",
            "content": "The extra lessons. of course, include drills that familiarise students with past exams. it is now\ntypical for senior secondary students to spend their August studying rather than relaxing\n\nHowever, those who have just entered university have a different lite to took forward to. Wide-\nranging electives. lectures delivered by accomplished academics, involvement in student activities\nand overseas exchanges conjure up exciting journeys that could have lasting influence on\nanyone's life.\n\nFor these students. it is the time to take ownership of their learning and dump the mindset of\nintensive coaching and drilling they were brought up in. The days of robotic studying for that life-\nshaping examination and being fed answers to the model are gone forever.\n\nUniversity study means thinking for themselves. a period of exploration. There are no fixed\nsyllabuses to adhere to, and how much they gain from the four-year period is pretty much of their\nown making. But getting top grades in ail subjects does not necessarily transiate into a high degree\nof employability. On the contrary, a well-rounded student could excel in the workplace better than\nthe one who's academically gifted\n\ncached aeeneesty i\n\npp Stone aco name pret toleaky bear da atari ERS VEOH peng at Daa aie ace ty oH eR\n\nPLO AOE Yoru eam hing the esaeataers epstien ome you've Araced ancveraly\n\nStudents choose whether to simply idle away the time on campus. indulge in activities at the\nexpense of academic study or. at the other extreme. bury themselves in books without paying\nregard to what is happening around them.\n"
        },
        {
            "date": "2022-12-31",
            "time": "13:37:45.824573",
            "file": "31_1672490259301.png",
            "content": "BOX 0 => 7"
        },
        {
            "date": "2022-12-31",
            "time": "13:41:58.215167",
            "file": "21_1672490517142.png",
            "content": "BOX 0 => 8"
        },
        {
            "date": "2022-12-31",
            "time": "13:43:07.749186",
            "file": "hdig_3_1672490586861.jpg",
            "content": "BOX 0 => 2, BOX 1 => 1"
        },
        {
            "date": "2022-12-31",
            "time": "13:43:35.764051",
            "file": "hdig_10_1672490615064.jpg",
            "content": "BOX 0 => 7, BOX 1 => 6"
        },
        {
            "date": "2022-12-31",
            "time": "13:44:07.217793",
            "file": "hdig_1_1672490642510.jpg",
            "content": "BOX 0 => 3, BOX 1 => 0, BOX 2 => 3, BOX 3 => 2, BOX 4 => 7, BOX 5 => 6, BOX 6 => 7, BOX 7 => 6, BOX 8 => 4, BOX 9 => 7, BOX 10 => 7, BOX 11 => 0, BOX 12 => 4, BOX 13 => 3, BOX 14 => 7, BOX 15 => 6, BOX 16 => 4, BOX 17 => 5, BOX 18 => 5, BOX 19 => 5, BOX 20 => 9, BOX 21 => 7, BOX 22 => 0, BOX 23 => 8, BOX 24 => 5, BOX 25 => 6, BOX 26 => 2, BOX 27 => 3, BOX 28 => 4, BOX 29 => 7"
        },
        {
            "date": "2022-12-31",
            "time": "13:50:47.141760",
            "file": "hdig_16_1672491045696.jpg",
            "content": "BOX 0 => 2"
        },
        {
            "date": "2022-12-31",
            "time": "13:52:15.173668",
            "file": "hdig_13_1672491134675.jpg",
            "content": "BOX 0 => 8, BOX 1 => G, BOX 2 => Q, BOX 3 => 7"
        },
        {
            "date": "2022-12-31",
            "time": "13:52:51.041853",
            "file": "hdig_7_1672491170651.jpg",
            "content": "BOX 0 => G, BOX 1 => 4, BOX 2 => 5"
        },
        {
            "date": "2022-12-31",
            "time": "13:53:07.472954",
            "file": "hdig_10_1672491187031.jpg",
            "content": "BOX 0 => R, BOX 1 => q"
        },
        {
            "date": "2022-12-31",
            "time": "13:54:11.001588",
            "file": "sample_0_1_c.png",
            "content": ""
        },
        {
            "date": "2022-12-31",
            "time": "14:03:43.968620",
            "file": "sample_1_1672491823419.png",
            "content": ""
        },
        {
            "date": "2022-12-31",
            "time": "14:05:18.029738",
            "file": "hdig_15_1672491917640.png",
            "content": ""
        },
        {
            "date": "2022-12-31",
            "time": "14:10:53.300091",
            "file": "hdig_6_1672492252775.jpg",
            "content": "BOX 0 => 2, BOX 1 => 2"
        },
        {
            "date": "2022-12-31",
            "time": "14:11:08.452655",
            "file": "hdig_7_1672492268063.jpg",
            "content": "BOX 0 => 9, BOX 1 => 8"
        },
        {
            "date": "2022-12-31",
            "time": "14:13:43.481663",
            "file": "hdig_7_1672492422591.jpg",
            "content": "BOX 0 => 6, BOX 1 => 7"
        },
        {
            "date": "2022-12-31",
            "time": "14:13:43.545867",
            "file": "hdig_7_1672492422601.jpg",
            "content": "BOX 0 => 6, BOX 1 => 7"
        },
        {
            "date": "2023-01-01",
            "time": "18:55:53.933250",
            "file": "sample_0_1_c.png",
            "content": ""
        },
        {
            "date": "2023-01-01",
            "time": "18:56:37.446324",
            "file": "paper_tesseract_handwriting_1_c.png",
            "content": "Pant oe at Soy ae Blanton ete 1\n\nRecognition of Handwritten Textual Annotations using Tesseract\n\u2018Open Source OCR Engine for information Just in Tine (id#T)\n\nSavwig Bakara\u201d Seren Ran, \u00e9 Maa thevts\n\n> tectens ata Cathe of Yacteetgy, thea cha\n\n Earmynine Scien ae! Engenetinn Dugaeenet, atirerar Urewoaty, eb\n\nteeecagies Deeb Syatacea Pmpaevinine, Corteat Renae fay. Bac\neva, agar\n\nCermprediong mittee Ford sthasiertbomen sey\nAbetract\n\n\u2018gerne of i st eh ee Sei ae CR Cant the ge EA see\nfee pene MD Hie GAT: ayn ics apd in gf Pai\nSever et cle Betton ws Sac pam eo ASE mgr tae ae\nwrt of en ce Rem aun) en ue XN carat cet Ao\noe he Ge aed etn Stan mat ae ety 6 etna et a ate\n(ne aig gar Se gen Fae ign en ar ay ly Sonat Sed i ed\nSeine tae tance eat at ae im Sef irae rk oetane oe\nSpe tat ay Tem Sega ont Bid. eg end seh ah mS om\nSrukeines wear ae hee ation, ihe, apc weed areal) ames moe\neee paily tengmee APRs BEAN PAWS AEE ed EA Sedat ane\nSep tes maria tte Stare? are\n\nA mrteedectien\n\nseatreat te teat Ne Brgy abate agen Hele Pe ok Neko\nTieememcante np ia tis te ketene aie eo\n\nTpeitey viet ard ekimpet wraps of onto hte tes ie a\nSeti: apidaten wa aman gee fo D0 ane tenga aes, ae\nserntitets \u00a9 Aaa eke a BBR oe tea panied\nTieng Partarien tga a SM atypia\nii lees acre red bated etl Pee ik meet Rae fw BC EB\n[Spteed aerucre of Meee gen Set tien Pe\u201c St te\nSaetranee te tach ekreet omiay ibe ae meg of\n\nSiemens ted cr iether ey Sit Gah AY Pa one te\nSeniesa ening aoe tend of Pane secon id or ater ree\nSag cintart ewe Glee of cud maae a Pye ga head\n\n\u2018a ay scerlion Gamat sabe ene, Re kira etree ete\npec of Saree Ri nee 9 Pa\nSys grime cheat) eis le cpr Grete te De inner ok ee\nween ban ated beaks een Pop aiid Gy one Pater\nceeghtee syomme PT ate me Shee geet Gna P3PER, a en\n\nfrahe si Arathi Aura 72 Or soar ae! nate OAT\nSean scene of cme om of Hye ere\n\n"
        },
        {
            "date": "2023-01-01",
            "time": "18:56:39.078364",
            "file": "paper_tesseract_handwriting_1_c.png",
            "content": "Pant oe at Soy ae Blanton ete 1\n\nRecognition of Handwritten Textual Annotations using Tesseract\n\u2018Open Source OCR Engine for information Just in Tine (id#T)\n\nSavwig Bakara\u201d Seren Ran, \u00e9 Maa thevts\n\n> tectens ata Cathe of Yacteetgy, thea cha\n\n Earmynine Scien ae! Engenetinn Dugaeenet, atirerar Urewoaty, eb\n\nteeecagies Deeb Syatacea Pmpaevinine, Corteat Renae fay. Bac\neva, agar\n\nCermprediong mittee Ford sthasiertbomen sey\nAbetract\n\n\u2018gerne of i st eh ee Sei ae CR Cant the ge EA see\nfee pene MD Hie GAT: ayn ics apd in gf Pai\nSever et cle Betton ws Sac pam eo ASE mgr tae ae\nwrt of en ce Rem aun) en ue XN carat cet Ao\noe he Ge aed etn Stan mat ae ety 6 etna et a ate\n(ne aig gar Se gen Fae ign en ar ay ly Sonat Sed i ed\nSeine tae tance eat at ae im Sef irae rk oetane oe\nSpe tat ay Tem Sega ont Bid. eg end seh ah mS om\nSrukeines wear ae hee ation, ihe, apc weed areal) ames moe\neee paily tengmee APRs BEAN PAWS AEE ed EA Sedat ane\nSep tes maria tte Stare? are\n\nA mrteedectien\n\nseatreat te teat Ne Brgy abate agen Hele Pe ok Neko\nTieememcante np ia tis te ketene aie eo\n\nTpeitey viet ard ekimpet wraps of onto hte tes ie a\nSeti: apidaten wa aman gee fo D0 ane tenga aes, ae\nserntitets \u00a9 Aaa eke a BBR oe tea panied\nTieng Partarien tga a SM atypia\nii lees acre red bated etl Pee ik meet Rae fw BC EB\n[Spteed aerucre of Meee gen Set tien Pe\u201c St te\nSaetranee te tach ekreet omiay ibe ae meg of\n\nSiemens ted cr iether ey Sit Gah AY Pa one te\nSeniesa ening aoe tend of Pane secon id or ater ree\nSag cintart ewe Glee of cud maae a Pye ga head\n\n\u2018a ay scerlion Gamat sabe ene, Re kira etree ete\npec of Saree Ri nee 9 Pa\nSys grime cheat) eis le cpr Grete te De inner ok ee\nween ban ated beaks een Pop aiid Gy one Pater\nceeghtee syomme PT ate me Shee geet Gna P3PER, a en\n\nfrahe si Arathi Aura 72 Or soar ae! nate OAT\nSean scene of cme om of Hye ere\n\n"
        },
        {
            "date": "2023-01-01",
            "time": "18:56:40.683993",
            "file": "paper_tesseract_handwriting_1_c.png",
            "content": "Pant oe at Soy ae Blanton ete 1\n\nRecognition of Handwritten Textual Annotations using Tesseract\n\u2018Open Source OCR Engine for information Just in Tine (id#T)\n\nSavwig Bakara\u201d Seren Ran, \u00e9 Maa thevts\n\n> tectens ata Cathe of Yacteetgy, thea cha\n\n Earmynine Scien ae! Engenetinn Dugaeenet, atirerar Urewoaty, eb\n\nteeecagies Deeb Syatacea Pmpaevinine, Corteat Renae fay. Bac\neva, agar\n\nCermprediong mittee Ford sthasiertbomen sey\nAbetract\n\n\u2018gerne of i st eh ee Sei ae CR Cant the ge EA see\nfee pene MD Hie GAT: ayn ics apd in gf Pai\nSever et cle Betton ws Sac pam eo ASE mgr tae ae\nwrt of en ce Rem aun) en ue XN carat cet Ao\noe he Ge aed etn Stan mat ae ety 6 etna et a ate\n(ne aig gar Se gen Fae ign en ar ay ly Sonat Sed i ed\nSeine tae tance eat at ae im Sef irae rk oetane oe\nSpe tat ay Tem Sega ont Bid. eg end seh ah mS om\nSrukeines wear ae hee ation, ihe, apc weed areal) ames moe\neee paily tengmee APRs BEAN PAWS AEE ed EA Sedat ane\nSep tes maria tte Stare? are\n\nA mrteedectien\n\nseatreat te teat Ne Brgy abate agen Hele Pe ok Neko\nTieememcante np ia tis te ketene aie eo\n\nTpeitey viet ard ekimpet wraps of onto hte tes ie a\nSeti: apidaten wa aman gee fo D0 ane tenga aes, ae\nserntitets \u00a9 Aaa eke a BBR oe tea panied\nTieng Partarien tga a SM atypia\nii lees acre red bated etl Pee ik meet Rae fw BC EB\n[Spteed aerucre of Meee gen Set tien Pe\u201c St te\nSaetranee te tach ekreet omiay ibe ae meg of\n\nSiemens ted cr iether ey Sit Gah AY Pa one te\nSeniesa ening aoe tend of Pane secon id or ater ree\nSag cintart ewe Glee of cud maae a Pye ga head\n\n\u2018a ay scerlion Gamat sabe ene, Re kira etree ete\npec of Saree Ri nee 9 Pa\nSys grime cheat) eis le cpr Grete te De inner ok ee\nween ban ated beaks een Pop aiid Gy one Pater\nceeghtee syomme PT ate me Shee geet Gna P3PER, a en\n\nfrahe si Arathi Aura 72 Or soar ae! nate OAT\nSean scene of cme om of Hye ere\n\n"
        },
        {
            "date": "2023-01-01",
            "time": "18:56:42.423372",
            "file": "paper_tesseract_handwriting_1_c.png",
            "content": "Pant oe at Soy ae Blanton ete 1\n\nRecognition of Handwritten Textual Annotations using Tesseract\n\u2018Open Source OCR Engine for information Just in Tine (id#T)\n\nSavwig Bakara\u201d Seren Ran, \u00e9 Maa thevts\n\n> tectens ata Cathe of Yacteetgy, thea cha\n\n Earmynine Scien ae! Engenetinn Dugaeenet, atirerar Urewoaty, eb\n\nteeecagies Deeb Syatacea Pmpaevinine, Corteat Renae fay. Bac\neva, agar\n\nCermprediong mittee Ford sthasiertbomen sey\nAbetract\n\n\u2018gerne of i st eh ee Sei ae CR Cant the ge EA see\nfee pene MD Hie GAT: ayn ics apd in gf Pai\nSever et cle Betton ws Sac pam eo ASE mgr tae ae\nwrt of en ce Rem aun) en ue XN carat cet Ao\noe he Ge aed etn Stan mat ae ety 6 etna et a ate\n(ne aig gar Se gen Fae ign en ar ay ly Sonat Sed i ed\nSeine tae tance eat at ae im Sef irae rk oetane oe\nSpe tat ay Tem Sega ont Bid. eg end seh ah mS om\nSrukeines wear ae hee ation, ihe, apc weed areal) ames moe\neee paily tengmee APRs BEAN PAWS AEE ed EA Sedat ane\nSep tes maria tte Stare? are\n\nA mrteedectien\n\nseatreat te teat Ne Brgy abate agen Hele Pe ok Neko\nTieememcante np ia tis te ketene aie eo\n\nTpeitey viet ard ekimpet wraps of onto hte tes ie a\nSeti: apidaten wa aman gee fo D0 ane tenga aes, ae\nserntitets \u00a9 Aaa eke a BBR oe tea panied\nTieng Partarien tga a SM atypia\nii lees acre red bated etl Pee ik meet Rae fw BC EB\n[Spteed aerucre of Meee gen Set tien Pe\u201c St te\nSaetranee te tach ekreet omiay ibe ae meg of\n\nSiemens ted cr iether ey Sit Gah AY Pa one te\nSeniesa ening aoe tend of Pane secon id or ater ree\nSag cintart ewe Glee of cud maae a Pye ga head\n\n\u2018a ay scerlion Gamat sabe ene, Re kira etree ete\npec of Saree Ri nee 9 Pa\nSys grime cheat) eis le cpr Grete te De inner ok ee\nween ban ated beaks een Pop aiid Gy one Pater\nceeghtee syomme PT ate me Shee geet Gna P3PER, a en\n\nfrahe si Arathi Aura 72 Or soar ae! nate OAT\nSean scene of cme om of Hye ere\n\n"
        },
        {
            "date": "2023-01-01",
            "time": "18:56:43.991427",
            "file": "paper_tesseract_handwriting_1_c.png",
            "content": "Pant oe at Soy ae Blanton ete 1\n\nRecognition of Handwritten Textual Annotations using Tesseract\n\u2018Open Source OCR Engine for information Just in Tine (id#T)\n\nSavwig Bakara\u201d Seren Ran, \u00e9 Maa thevts\n\n> tectens ata Cathe of Yacteetgy, thea cha\n\n Earmynine Scien ae! Engenetinn Dugaeenet, atirerar Urewoaty, eb\n\nteeecagies Deeb Syatacea Pmpaevinine, Corteat Renae fay. Bac\neva, agar\n\nCermprediong mittee Ford sthasiertbomen sey\nAbetract\n\n\u2018gerne of i st eh ee Sei ae CR Cant the ge EA see\nfee pene MD Hie GAT: ayn ics apd in gf Pai\nSever et cle Betton ws Sac pam eo ASE mgr tae ae\nwrt of en ce Rem aun) en ue XN carat cet Ao\noe he Ge aed etn Stan mat ae ety 6 etna et a ate\n(ne aig gar Se gen Fae ign en ar ay ly Sonat Sed i ed\nSeine tae tance eat at ae im Sef irae rk oetane oe\nSpe tat ay Tem Sega ont Bid. eg end seh ah mS om\nSrukeines wear ae hee ation, ihe, apc weed areal) ames moe\neee paily tengmee APRs BEAN PAWS AEE ed EA Sedat ane\nSep tes maria tte Stare? are\n\nA mrteedectien\n\nseatreat te teat Ne Brgy abate agen Hele Pe ok Neko\nTieememcante np ia tis te ketene aie eo\n\nTpeitey viet ard ekimpet wraps of onto hte tes ie a\nSeti: apidaten wa aman gee fo D0 ane tenga aes, ae\nserntitets \u00a9 Aaa eke a BBR oe tea panied\nTieng Partarien tga a SM atypia\nii lees acre red bated etl Pee ik meet Rae fw BC EB\n[Spteed aerucre of Meee gen Set tien Pe\u201c St te\nSaetranee te tach ekreet omiay ibe ae meg of\n\nSiemens ted cr iether ey Sit Gah AY Pa one te\nSeniesa ening aoe tend of Pane secon id or ater ree\nSag cintart ewe Glee of cud maae a Pye ga head\n\n\u2018a ay scerlion Gamat sabe ene, Re kira etree ete\npec of Saree Ri nee 9 Pa\nSys grime cheat) eis le cpr Grete te De inner ok ee\nween ban ated beaks een Pop aiid Gy one Pater\nceeghtee syomme PT ate me Shee geet Gna P3PER, a en\n\nfrahe si Arathi Aura 72 Or soar ae! nate OAT\nSean scene of cme om of Hye ere\n\n"
        },
        {
            "date": "2023-01-01",
            "time": "18:56:45.542753",
            "file": "paper_tesseract_handwriting_1_c.png",
            "content": "Pant oe at Soy ae Blanton ete 1\n\nRecognition of Handwritten Textual Annotations using Tesseract\n\u2018Open Source OCR Engine for information Just in Tine (id#T)\n\nSavwig Bakara\u201d Seren Ran, \u00e9 Maa thevts\n\n> tectens ata Cathe of Yacteetgy, thea cha\n\n Earmynine Scien ae! Engenetinn Dugaeenet, atirerar Urewoaty, eb\n\nteeecagies Deeb Syatacea Pmpaevinine, Corteat Renae fay. Bac\neva, agar\n\nCermprediong mittee Ford sthasiertbomen sey\nAbetract\n\n\u2018gerne of i st eh ee Sei ae CR Cant the ge EA see\nfee pene MD Hie GAT: ayn ics apd in gf Pai\nSever et cle Betton ws Sac pam eo ASE mgr tae ae\nwrt of en ce Rem aun) en ue XN carat cet Ao\noe he Ge aed etn Stan mat ae ety 6 etna et a ate\n(ne aig gar Se gen Fae ign en ar ay ly Sonat Sed i ed\nSeine tae tance eat at ae im Sef irae rk oetane oe\nSpe tat ay Tem Sega ont Bid. eg end seh ah mS om\nSrukeines wear ae hee ation, ihe, apc weed areal) ames moe\neee paily tengmee APRs BEAN PAWS AEE ed EA Sedat ane\nSep tes maria tte Stare? are\n\nA mrteedectien\n\nseatreat te teat Ne Brgy abate agen Hele Pe ok Neko\nTieememcante np ia tis te ketene aie eo\n\nTpeitey viet ard ekimpet wraps of onto hte tes ie a\nSeti: apidaten wa aman gee fo D0 ane tenga aes, ae\nserntitets \u00a9 Aaa eke a BBR oe tea panied\nTieng Partarien tga a SM atypia\nii lees acre red bated etl Pee ik meet Rae fw BC EB\n[Spteed aerucre of Meee gen Set tien Pe\u201c St te\nSaetranee te tach ekreet omiay ibe ae meg of\n\nSiemens ted cr iether ey Sit Gah AY Pa one te\nSeniesa ening aoe tend of Pane secon id or ater ree\nSag cintart ewe Glee of cud maae a Pye ga head\n\n\u2018a ay scerlion Gamat sabe ene, Re kira etree ete\npec of Saree Ri nee 9 Pa\nSys grime cheat) eis le cpr Grete te De inner ok ee\nween ban ated beaks een Pop aiid Gy one Pater\nceeghtee syomme PT ate me Shee geet Gna P3PER, a en\n\nfrahe si Arathi Aura 72 Or soar ae! nate OAT\nSean scene of cme om of Hye ere\n\n"
        },
        {
            "date": "2023-01-01",
            "time": "18:56:47.195280",
            "file": "paper_tesseract_handwriting_1_c.png",
            "content": "Pant oe at Soy ae Blanton ete 1\n\nRecognition of Handwritten Textual Annotations using Tesseract\n\u2018Open Source OCR Engine for information Just in Tine (id#T)\n\nSavwig Bakara\u201d Seren Ran, \u00e9 Maa thevts\n\n> tectens ata Cathe of Yacteetgy, thea cha\n\n Earmynine Scien ae! Engenetinn Dugaeenet, atirerar Urewoaty, eb\n\nteeecagies Deeb Syatacea Pmpaevinine, Corteat Renae fay. Bac\neva, agar\n\nCermprediong mittee Ford sthasiertbomen sey\nAbetract\n\n\u2018gerne of i st eh ee Sei ae CR Cant the ge EA see\nfee pene MD Hie GAT: ayn ics apd in gf Pai\nSever et cle Betton ws Sac pam eo ASE mgr tae ae\nwrt of en ce Rem aun) en ue XN carat cet Ao\noe he Ge aed etn Stan mat ae ety 6 etna et a ate\n(ne aig gar Se gen Fae ign en ar ay ly Sonat Sed i ed\nSeine tae tance eat at ae im Sef irae rk oetane oe\nSpe tat ay Tem Sega ont Bid. eg end seh ah mS om\nSrukeines wear ae hee ation, ihe, apc weed areal) ames moe\neee paily tengmee APRs BEAN PAWS AEE ed EA Sedat ane\nSep tes maria tte Stare? are\n\nA mrteedectien\n\nseatreat te teat Ne Brgy abate agen Hele Pe ok Neko\nTieememcante np ia tis te ketene aie eo\n\nTpeitey viet ard ekimpet wraps of onto hte tes ie a\nSeti: apidaten wa aman gee fo D0 ane tenga aes, ae\nserntitets \u00a9 Aaa eke a BBR oe tea panied\nTieng Partarien tga a SM atypia\nii lees acre red bated etl Pee ik meet Rae fw BC EB\n[Spteed aerucre of Meee gen Set tien Pe\u201c St te\nSaetranee te tach ekreet omiay ibe ae meg of\n\nSiemens ted cr iether ey Sit Gah AY Pa one te\nSeniesa ening aoe tend of Pane secon id or ater ree\nSag cintart ewe Glee of cud maae a Pye ga head\n\n\u2018a ay scerlion Gamat sabe ene, Re kira etree ete\npec of Saree Ri nee 9 Pa\nSys grime cheat) eis le cpr Grete te De inner ok ee\nween ban ated beaks een Pop aiid Gy one Pater\nceeghtee syomme PT ate me Shee geet Gna P3PER, a en\n\nfrahe si Arathi Aura 72 Or soar ae! nate OAT\nSean scene of cme om of Hye ere\n\n"
        },
        {
            "date": "2023-01-01",
            "time": "18:56:48.761299",
            "file": "paper_tesseract_handwriting_1_c.png",
            "content": "Pant oe at Soy ae Blanton ete 1\n\nRecognition of Handwritten Textual Annotations using Tesseract\n\u2018Open Source OCR Engine for information Just in Tine (id#T)\n\nSavwig Bakara\u201d Seren Ran, \u00e9 Maa thevts\n\n> tectens ata Cathe of Yacteetgy, thea cha\n\n Earmynine Scien ae! Engenetinn Dugaeenet, atirerar Urewoaty, eb\n\nteeecagies Deeb Syatacea Pmpaevinine, Corteat Renae fay. Bac\neva, agar\n\nCermprediong mittee Ford sthasiertbomen sey\nAbetract\n\n\u2018gerne of i st eh ee Sei ae CR Cant the ge EA see\nfee pene MD Hie GAT: ayn ics apd in gf Pai\nSever et cle Betton ws Sac pam eo ASE mgr tae ae\nwrt of en ce Rem aun) en ue XN carat cet Ao\noe he Ge aed etn Stan mat ae ety 6 etna et a ate\n(ne aig gar Se gen Fae ign en ar ay ly Sonat Sed i ed\nSeine tae tance eat at ae im Sef irae rk oetane oe\nSpe tat ay Tem Sega ont Bid. eg end seh ah mS om\nSrukeines wear ae hee ation, ihe, apc weed areal) ames moe\neee paily tengmee APRs BEAN PAWS AEE ed EA Sedat ane\nSep tes maria tte Stare? are\n\nA mrteedectien\n\nseatreat te teat Ne Brgy abate agen Hele Pe ok Neko\nTieememcante np ia tis te ketene aie eo\n\nTpeitey viet ard ekimpet wraps of onto hte tes ie a\nSeti: apidaten wa aman gee fo D0 ane tenga aes, ae\nserntitets \u00a9 Aaa eke a BBR oe tea panied\nTieng Partarien tga a SM atypia\nii lees acre red bated etl Pee ik meet Rae fw BC EB\n[Spteed aerucre of Meee gen Set tien Pe\u201c St te\nSaetranee te tach ekreet omiay ibe ae meg of\n\nSiemens ted cr iether ey Sit Gah AY Pa one te\nSeniesa ening aoe tend of Pane secon id or ater ree\nSag cintart ewe Glee of cud maae a Pye ga head\n\n\u2018a ay scerlion Gamat sabe ene, Re kira etree ete\npec of Saree Ri nee 9 Pa\nSys grime cheat) eis le cpr Grete te De inner ok ee\nween ban ated beaks een Pop aiid Gy one Pater\nceeghtee syomme PT ate me Shee geet Gna P3PER, a en\n\nfrahe si Arathi Aura 72 Or soar ae! nate OAT\nSean scene of cme om of Hye ere\n\n"
        },
        {
            "date": "2023-01-06",
            "time": "12:57:24.333807",
            "file": "web_app/static/sample_0.pdf p.0",
            "content": "Hello World \nHello World1 \n \nHello World2 \n \n \nHello World3 \n \n \nHello World4 \nHello World5 \nHello World6 \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "12:57:35.218021",
            "file": "web_app/static/sample_5_1673006255081.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "12:58:05.873742",
            "file": "news_1.webp_1673006285582.webp",
            "content": "Civic Society during what will\nhopefully be a positive outcome\n$ the consideration of 9 fixture\ntheatre in the centre of Bxeter\u201d\n"
        },
        {
            "date": "2023-01-06",
            "time": "13:54:21.550141",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "13:57:05.367098",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "13:58:27.218803",
            "file": "web_app/static/hand_test.pdf p.0",
            "content": " \n"
        },
        {
            "date": "2023-01-06",
            "time": "13:58:33.649819",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "13:59:00.301920",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "13:59:46.620382",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "<div id=\"page0\" style=\"width:595.3pt;height:841.9pt\">\n<p style=\"top:72.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">R </span></p>\n<p style=\"top:95.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:117.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:140.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:162.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:185.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:207.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:106.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:141.6pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:177.0pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:212.4pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:247.9pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:283.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:318.7pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:354.1pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:389.5pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:424.9pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:460.3pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">Sdf </span></p>\n<p style=\"top:252.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:274.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:297.5pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">Pzicn </span></p>\n<p style=\"top:319.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:342.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:106.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:141.6pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:177.0pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:212.4pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">udchd </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:01:20.065131",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "<div id=\"page0\" style=\"width:595.3pt;height:841.9pt\">\n<p style=\"top:72.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">R </span></p>\n<p style=\"top:95.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:117.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:140.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:162.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:185.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:207.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:106.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:141.6pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:177.0pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:212.4pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:247.9pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:283.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:318.7pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:354.1pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:389.5pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:424.9pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:460.3pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">Sdf </span></p>\n<p style=\"top:252.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:274.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:297.5pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">Pzicn </span></p>\n<p style=\"top:319.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:342.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:106.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:141.6pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:177.0pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:212.4pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">udchd </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:03:57.008873",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "<div id=\"page0\" style=\"width:595.3pt;height:841.9pt\">\n<p style=\"top:72.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">R </span></p>\n<p style=\"top:95.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:117.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:140.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:162.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:185.0pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:207.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:106.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:141.6pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:177.0pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:212.4pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:247.9pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:283.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:318.7pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:354.1pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:389.5pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:424.9pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:229.9pt;left:460.3pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">Sdf </span></p>\n<p style=\"top:252.4pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:274.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:297.5pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">Pzicn </span></p>\n<p style=\"top:319.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:342.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:106.2pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:141.6pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:177.0pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:364.9pt;left:212.4pt;line-height:11.0pt\"><span style=\"font-family:Calibri,sans-serif;font-size:11.0pt\">udchd </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:04:16.026054",
            "file": "web_app/static/sample_0.pdf p.0",
            "content": "<div id=\"page0\" style=\"width:595.3pt;height:841.9pt\">\n<p style=\"top:71.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World </span></p>\n<p style=\"top:94.1pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World1 </span></p>\n<p style=\"top:116.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:139.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World2 </span></p>\n<p style=\"top:162.7pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:185.5pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:208.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World3 </span></p>\n<p style=\"top:231.1pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:253.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:276.7pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World4 </span></p>\n<p style=\"top:299.5pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World5 </span></p>\n<p style=\"top:322.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World6 </span></p>\n<p style=\"top:345.1pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:05:24.470809",
            "file": "web_app/static/paper_tesseract_handwriting.pdf p.0",
            "content": "<div id=\"page0\" style=\"width:595.0pt;height:842.0pt\">\n<p style=\"top:71.9pt;left:181.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Proc. Int. Conf. on Information Technology and Business Intelligence (2009) 117-125 </span></p>\n<p style=\"top:92.9pt;left:89.1pt;line-height:13.6pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:13.6pt\">Recognition of Handwritten Textual Annotations using Tesseract </span></b></p>\n<p style=\"top:108.6pt;left:103.7pt;line-height:13.6pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:13.6pt\">Open Source OCR Engine for </span></b><b><i><span style=\"font-family:Arial,sans-serif;font-size:13.6pt\">information Just In Time (iJIT) </span></i></b></p>\n<p style=\"top:123.8pt;left:297.6pt;line-height:10.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:10.7pt\"> </span></b></p>\n<p style=\"top:136.1pt;left:297.6pt;line-height:10.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:10.7pt\"> </span></b></p>\n<p style=\"top:148.5pt;left:164.8pt;line-height:11.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> Sandip Rakshit </span><sup><span style=\"font-family:Arial,sans-serif;font-size:7.8pt\">1</span></sup><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">, Subhadip Basu </span><sup><span style=\"font-family:Arial,sans-serif;font-size:7.8pt\">2</span></sup><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">, Hisashi Ikeda</span><sup><span style=\"font-family:Arial,sans-serif;font-size:7.8pt\"> 3 </span></sup></p>\n<p style=\"top:162.0pt;left:297.6pt;line-height:11.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:173.1pt;left:163.8pt;line-height:7.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:7.8pt\">1</span><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> Techno India</span><i><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> </span></i><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">College of Technology, Kolkata, India</span><i><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> </span></i></p>\n<p style=\"top:186.6pt;left:99.7pt;line-height:7.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:7.8pt\">2</span><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> Computer Science and Engineering Department, Jadavpur University, India</span><span style=\"font-family:Arial,sans-serif;font-size:7.8pt\">  </span></p>\n<p style=\"top:200.0pt;left:95.8pt;line-height:7.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:7.8pt\">3 </span><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> Intelligent Media Systems Department, Central Research Laboratoty, Hitachi </span></p>\n<p style=\"top:215.6pt;left:259.7pt;line-height:11.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">Limited, Japan </span></p>\n<p style=\"top:229.0pt;left:297.6pt;line-height:11.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:240.2pt;left:164.0pt;line-height:7.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:7.8pt\">1</span><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> Corresponding author. E-mail: subhadip@ieee.org  </span></p>\n<p style=\"top:255.9pt;left:297.6pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></b></p>\n<p style=\"top:269.3pt;left:87.5pt;line-height:11.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">Abstract </span></b></p>\n<p style=\"top:282.7pt;left:87.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></b></p>\n<p style=\"top:295.9pt;left:87.5pt;line-height:9.7pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></i></p>\n<p style=\"top:295.9pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Objective of the current work is to develop an Optical Character Recognition (OCR) engine </span></p>\n<p style=\"top:307.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">for information Just In Time (iJIT) system that can be used for recognition of handwritten textual </span></p>\n<p style=\"top:318.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">annotations of lower case Roman script. Tesseract open source OCR engine under Apache </span></p>\n<p style=\"top:329.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">License 2.0 is used to develop user-specific handwriting recognition models, viz., the language </span></p>\n<p style=\"top:340.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">sets, for the said system, where each user is identified by a unique identification tag associated </span></p>\n<p style=\"top:351.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">with the digital pen. To generate the language set for any user, Tesseract is trained with labeled </span></p>\n<p style=\"top:362.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">handwritten data samples of isolated and free-flow texts of Roman script, collected exclusively </span></p>\n<p style=\"top:374.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">from that user. The designed system is tested on five different language sets with free- flow </span></p>\n<p style=\"top:385.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">handwritten annotations as test samples. The system could successfully segment and </span></p>\n<p style=\"top:396.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">subsequently recognize 87.92%, 81.53%, 92.88%, 86.75% and 90.80% handwritten characters in </span></p>\n<p style=\"top:407.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">the test samples of five different users</span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">. </span></i></p>\n<p style=\"top:419.1pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:432.6pt;left:87.5pt;line-height:11.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">1. Introduction </span></b></p>\n<p style=\"top:445.8pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:457.6pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:459.1pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">In online character recognition, the trajectories of pen tip movements are recorded and </span></p>\n<p style=\"top:470.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">analyzed to identify the linguistic information expressed. With the latest technological </span></p>\n<p style=\"top:481.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">advancements in pen input devices, new interfaces are designed to capture the precise pen-</span></p>\n<p style=\"top:492.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">trajectory information and subsequent analysis of online handwritten data, with user comforts in </span></p>\n<p style=\"top:503.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">writing. It is now possible to write on an ordinary paper and immediate wireless transmission of </span></p>\n<p style=\"top:515.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">handwritten annotations to a remote server [1]. With these technological advances, handwritten </span></p>\n<p style=\"top:526.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">annotations in digital notebooks may be digitized in no time. </span></p>\n<p style=\"top:526.2pt;left:363.3pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Traditionally, </span></p>\n<p style=\"top:526.2pt;left:460.2pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">documents </span></p>\n<p style=\"top:537.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">containing handwritten information are difficult to archive in digital form. Even with the help of </span></p>\n<p style=\"top:548.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">latest optical scanners, content based indexing techniques and research tools; it is difficult to find </span></p>\n<p style=\"top:559.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">digitized versions of document pages based on user queries. Some work has recently been done </span></p>\n<p style=\"top:571.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">on content based retrieval of handwritten documents [2-4]. In [2], Bertrand et.al. have developed </span></p>\n<p style=\"top:582.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">a technique for structural document recognition and recognition of handwritten names. In another </span></p>\n<p style=\"top:593.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">work, Matthew et.al. [3] developed a stroke feature based technique for retrieval of handwritten </span></p>\n<p style=\"top:604.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Chinese annotations based on typed/handwritten query. Srihari et.al. [4] had used stroke/shape </span></p>\n<p style=\"top:615.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">features for indexing and retrieval of handwritten documents based on writer characteristics, </span></p>\n<p style=\"top:626.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">textual content and writer profile. In one of our earlier works [5], a recognition based indexing </span></p>\n<p style=\"top:638.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">technique was discussed for real-time retrieval of handwritten annotations based on </span></p>\n<p style=\"top:649.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">typed/handwritten query. David Doermann, in his survey [6], had highlighted key issues involved </span></p>\n<p style=\"top:660.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">in indexing and retrieval of document images. </span></p>\n<p style=\"top:671.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:671.6pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">In any recognition based indexing technique, the overall performance predominantly depends </span></p>\n<p style=\"top:682.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">on accuracy of the underlying recognition engine. Development of a handwritten OCR engine with </span></p>\n<p style=\"top:694.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">high recognition accuracy is a still an open problem for the research community. Lot of research </span></p>\n<p style=\"top:705.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">efforts have already been reported [7-9] on different key aspects of handwritten character </span></p>\n<p style=\"top:716.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">recognition systems. In this work, we have used Tesseract 2.01 [10], an open source OCR </span></p>\n<p style=\"top:727.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Engine under Apache License 2.0, for segmentation and subsequent recognition of handwritten </span></p>\n<p style=\"top:738.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">textual annotations of lower case of </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Roman</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> script.  </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:05:24.579933",
            "file": "web_app/static/paper_tesseract_handwriting.pdf p.1",
            "content": "<div id=\"page0\" style=\"width:595.0pt;height:842.0pt\">\n<p style=\"top:71.9pt;left:181.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Proc. Int. Conf. on Information Technology and Business Intelligence (2009) 117-125 </span></p>\n<p style=\"top:92.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:92.3pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Objective of the current work is to develop an Optical Character Recognition (OCR) engine </span></p>\n<p style=\"top:103.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">for the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> system that can be used for recognition of handwritten textual annotations of lower </span></p>\n<p style=\"top:114.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">case </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Roman </span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">script. Tesseract is used to develop user-specific handwriting recognition models, </span></p>\n<p style=\"top:125.9pt;left:87.5pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">viz.</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">, the language sets, for the said system. Each user of the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT </span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">system may be identified by a </span></p>\n<p style=\"top:137.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">unique identification tag associated with the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Anoto</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> digital pen [1]. Tesseract OCR engine is </span></p>\n<p style=\"top:148.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">customized to perform user specific training on labeled handwriting samples of both isolated and </span></p>\n<p style=\"top:159.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">free-flow texts, written using lower case </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Roman</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> script. The performance is evaluated on both the </span></p>\n<p style=\"top:170.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">categories of document pages for observation of segmentation and character recognition </span></p>\n<p style=\"top:181.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">accuracies.  </span></p>\n<p style=\"top:193.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:193.0pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">The following sections describe an overview of the existing </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> system, an overview of the </span></p>\n<p style=\"top:204.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract OCR engine and the present experiment on designing an OCR engine for </span></p>\n<p style=\"top:215.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">segmentation and recognition of handwritten textual annotations</span><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">. </span></p>\n<p style=\"top:226.8pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:240.3pt;left:87.5pt;line-height:11.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">2. The </span></b><b><i><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">iJIT  </span></i></b><b><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">system </span></b></p>\n<p style=\"top:253.7pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:265.3pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:266.8pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Just in time availability of meaningful information is the key to any real-time information </span></p>\n<p style=\"top:278.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">retrieval system. The </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">information Just In Time (iJIT) </span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">system [5], developed at the Hitachi Central </span></p>\n<p style=\"top:289.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Research Laboratory, keeps track of all the digital documents stored in the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> server. Using the </span></p>\n<p style=\"top:300.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">proposed system, handwritten annotations on the printed digital document pages using </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Anoto</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:311.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">digital pens [1] may be viewed/shared/searched based on typed/handwritten query. Fig. 1. shows </span></p>\n<p style=\"top:322.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">a schematic overview of the recognition based query retrieval scheme designed for the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:334.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">system. </span></p>\n<p style=\"top:345.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:345.1pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">The </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> system uses ordinary papers, attached with digitally legible patent-protected dot-</span></p>\n<p style=\"top:356.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">patterns from </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Anoto</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> [1], for printout of each digital document through the server. The </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Anoto</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:367.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">patterns consist of numerous nearly invisible, intelligent black dots that can be read by a digital </span></p>\n<p style=\"top:378.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">pen. The pattern on each paper is unique so that each page can be kept separate from one </span></p>\n<p style=\"top:389.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">another. </span></p>\n<p style=\"top:401.2pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<img style=\"position:absolute;transform:matrix(1.3411448,0,-0,1.4151553,171.47998,588.4796)\" src=\"data:image/png;base64,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\nD083IbJBknEHAAAAAElFTkSuQmCC\">\n<p style=\"top:578.9pt;left:389.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:587.9pt;left:90.2pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Fig. 1. A schematic architecture of the recognition based query retrieval system. </span></p>\n<p style=\"top:599.3pt;left:90.2pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:615.4pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:615.4pt;left:105.1pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:627.1pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:628.7pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">An </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Anoto</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> digital pen [1], looks like its normal ballpoint counterpart, contains an integrated </span></p>\n<p style=\"top:639.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">digital camera, an advanced image microprocessor and a wireless communication device. The </span></p>\n<p style=\"top:651.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">pen can take around 50 digital snapshots per second, can store up to 50 full A4/letter size pages </span></p>\n<p style=\"top:662.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">of handwritten data and then securely send the information to the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> server through wireless </span></p>\n<p style=\"top:673.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">communication or </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Universal Serial Bus (USB)</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">. Every snapshot contains enough data to </span></p>\n<p style=\"top:684.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">determine the exact position of the pen in the paper, the time of pen-stroke and the unique </span></p>\n<p style=\"top:695.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">identification number of the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Anoto</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> paper. Each pen is also having unique identification numbers </span></p>\n<p style=\"top:706.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">so that the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> system can distinguish between every individual&#x2019;s handwriting.  </span></p>\n<p style=\"top:718.3pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:731.8pt;left:87.5pt;line-height:11.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">3. Overview of the Tesseract OCR engine </span></b></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:05:24.620933",
            "file": "web_app/static/paper_tesseract_handwriting.pdf p.2",
            "content": "<div id=\"page0\" style=\"width:595.0pt;height:842.0pt\">\n<p style=\"top:71.9pt;left:181.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Proc. Int. Conf. on Information Technology and Business Intelligence (2009) 117-125 </span></p>\n<p style=\"top:92.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:103.5pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract is an open source (under Apache License 2.0) offline optical character recognition </span></p>\n<p style=\"top:114.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">engine, originally developed at Hewlett Packard from 1984 to 1994. Tesseract is now partially </span></p>\n<p style=\"top:125.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">funded by Google [10] and released under the Apache license, version 2.0. The latest version, </span></p>\n<p style=\"top:137.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract 2.03 is released in April, 2008. In the current work, we have used Tesseract version </span></p>\n<p style=\"top:148.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">2.01, released in August 2007. </span></p>\n<p style=\"top:159.4pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Like any standard OCR engine, Tesseract is developed on top of the key functional modules </span></p>\n<p style=\"top:170.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">like, line and word finder, word recognizer, static character classifier, linguistic analyzer and an </span></p>\n<p style=\"top:181.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">adaptive classifier. However, it does not support document layout analysis, output formatting and </span></p>\n<p style=\"top:193.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">graphical user interface. Currently, Tesseract can recognize printed text written in English, </span></p>\n<p style=\"top:204.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Spanish, French, Italian, Dutch, German and various other languages. </span></p>\n<p style=\"top:215.3pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">To train Tesseract in English language 8 data files are required in tessdata sub directory. The 8 </span></p>\n<p style=\"top:226.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">files used for English are to be generated as follows:  </span></p>\n<p style=\"top:237.7pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tessdata/eng.freq-dawg  </span></p>\n<p style=\"top:248.9pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tessdata/eng.word-dawg  </span></p>\n<p style=\"top:260.1pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tessdata/eng.user-words  </span></p>\n<p style=\"top:271.3pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tessdata/eng.inttemp  </span></p>\n<p style=\"top:282.4pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tessdata/eng.normproto  </span></p>\n<p style=\"top:293.6pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tessdata/eng.pffmtable  </span></p>\n<p style=\"top:304.9pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tessdata/eng.unicharset  </span></p>\n<p style=\"top:316.0pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tessdata/eng.DangAmbigs </span></p>\n<p style=\"top:327.2pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:338.4pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:349.8pt;left:99.4pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></b></p>\n<p style=\"top:363.2pt;left:87.5pt;line-height:11.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">4.  The present work </span></b></p>\n<p style=\"top:376.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:387.6pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">In the current work, Tesseract 2.01 is used for developing user-specific handwriting recognition </span></p>\n<p style=\"top:398.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">models, </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">viz.</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">, the language sets, for the </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT </span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">system. To generate the language sets for each user, </span></p>\n<p style=\"top:409.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract is trained with labeled handwritten data samples of isolated and free-flow texts of lower </span></p>\n<p style=\"top:421.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">case </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Roman</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> script. Key functional modules of the developed system are discussed in the </span></p>\n<p style=\"top:432.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">following sub-sections. </span></p>\n<p style=\"top:443.5pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:454.6pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:466.0pt;left:87.5pt;line-height:10.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:10.7pt\">4.1. Collection of the dataset </span></b></p>\n<p style=\"top:478.1pt;left:105.1pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></b></p>\n<p style=\"top:489.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">For preparation of the dataset for the current experiment, digitized handwritten samples of lower </span></p>\n<p style=\"top:500.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">case </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Roman</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> script were collected from five different users. Six handwritten document pages, </span></p>\n<p style=\"top:511.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">consisting of isolated characters and free-flow words were collected from each of the users of the </span></p>\n<p style=\"top:522.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">designed system. These pages are categorized into two datasets. Dataset-1 consists of four </span></p>\n<p style=\"top:534.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">pages of isolated handwritten lower case </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Roman</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> characters and Dataset-2 constitutes two pages </span></p>\n<p style=\"top:545.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">of free-flow handwritten words, written from technical articles. For each user, three pages from </span></p>\n<p style=\"top:556.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">the dataset-1 and one page from the dataset-2 were considered for training the Tesseract OCR </span></p>\n<p style=\"top:567.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">engine. The remaining two pages, one from each dataset, constitute the test set for the current </span></p>\n<p style=\"top:578.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">experiment. The overall distribution of the character samples in the training and the test sets for </span></p>\n<p style=\"top:590.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">the five users is shown in Table 1. </span></p>\n<p style=\"top:601.0pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:612.4pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:623.5pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:634.7pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:645.9pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:657.1pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:668.2pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:679.4pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:690.7pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:701.8pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:713.0pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:724.2pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:735.4pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:05:24.654931",
            "file": "web_app/static/paper_tesseract_handwriting.pdf p.3",
            "content": "<div id=\"page0\" style=\"width:595.0pt;height:842.0pt\">\n<p style=\"top:71.9pt;left:181.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Proc. Int. Conf. on Information Technology and Business Intelligence (2009) 117-125 </span></p>\n<p style=\"top:92.3pt;left:114.7pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Table 1. Composition of the training and test set character samples for different users </span></p>\n<p style=\"top:103.5pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:114.6pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:129.3pt;left:175.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></b></p>\n<p style=\"top:129.3pt;left:257.8pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Dataset-1 </span></b></p>\n<p style=\"top:129.3pt;left:319.3pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Dataset-2</span></b></p>\n<p style=\"top:129.3pt;left:376.2pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Overall</span></b></p>\n<p style=\"top:149.5pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Train set </span></b></p>\n<p style=\"top:149.4pt;left:270.0pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1185 </span></p>\n<p style=\"top:149.4pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">659 </span></p>\n<p style=\"top:149.4pt;left:383.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1844 </span></p>\n<p style=\"top:149.5pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">U</span></b></p>\n<p style=\"top:162.9pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">s</span></b></p>\n<p style=\"top:176.3pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">e</span></b></p>\n<p style=\"top:189.7pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">r </span></b></p>\n<p style=\"top:203.2pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1 </span></b></p>\n<p style=\"top:171.4pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Test set  </span></b></p>\n<p style=\"top:171.3pt;left:272.7pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">442 </span></p>\n<p style=\"top:171.3pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">691 </span></p>\n<p style=\"top:171.3pt;left:383.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1133 </span></p>\n<p style=\"top:222.4pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Train set </span></b></p>\n<p style=\"top:222.3pt;left:269.8pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1006 </span></p>\n<p style=\"top:222.3pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">529 </span></p>\n<p style=\"top:222.3pt;left:383.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1535 </span></p>\n<p style=\"top:222.4pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">U</span></b></p>\n<p style=\"top:235.8pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">s</span></b></p>\n<p style=\"top:249.3pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">e</span></b></p>\n<p style=\"top:262.7pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">r </span></b></p>\n<p style=\"top:276.1pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">2 </span></b></p>\n<p style=\"top:244.3pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Test set  </span></b></p>\n<p style=\"top:244.2pt;left:272.7pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">468 </span></p>\n<p style=\"top:244.2pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">718 </span></p>\n<p style=\"top:244.2pt;left:383.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1186 </span></p>\n<p style=\"top:295.3pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Train set </span></b></p>\n<p style=\"top:295.2pt;left:272.7pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">992 </span></p>\n<p style=\"top:295.2pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">884 </span></p>\n<p style=\"top:295.2pt;left:383.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1876 </span></p>\n<p style=\"top:295.3pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">U</span></b></p>\n<p style=\"top:308.8pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">s</span></b></p>\n<p style=\"top:322.2pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">e</span></b></p>\n<p style=\"top:335.6pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">r </span></b></p>\n<p style=\"top:349.0pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">3 </span></b></p>\n<p style=\"top:317.3pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Test set  </span></b></p>\n<p style=\"top:317.2pt;left:272.7pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">546 </span></p>\n<p style=\"top:317.2pt;left:331.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1004 </span></p>\n<p style=\"top:317.2pt;left:383.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1550 </span></p>\n<p style=\"top:368.3pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Train set </span></b></p>\n<p style=\"top:368.2pt;left:272.7pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">619 </span></p>\n<p style=\"top:368.2pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">578 </span></p>\n<p style=\"top:368.2pt;left:383.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1197 </span></p>\n<p style=\"top:368.3pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">U</span></b></p>\n<p style=\"top:381.7pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">s</span></b></p>\n<p style=\"top:395.1pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">e</span></b></p>\n<p style=\"top:408.6pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">r </span></b></p>\n<p style=\"top:422.0pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">4 </span></b></p>\n<p style=\"top:390.3pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Test set  </span></b></p>\n<p style=\"top:390.1pt;left:272.7pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">260 </span></p>\n<p style=\"top:390.1pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">751 </span></p>\n<p style=\"top:390.1pt;left:383.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">1011 </span></p>\n<p style=\"top:441.3pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Train set </span></b></p>\n<p style=\"top:441.1pt;left:272.7pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">467 </span></p>\n<p style=\"top:441.1pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">255 </span></p>\n<p style=\"top:441.1pt;left:386.2pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">722 </span></p>\n<p style=\"top:441.3pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">U</span></b></p>\n<p style=\"top:454.6pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">s</span></b></p>\n<p style=\"top:468.1pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">e</span></b></p>\n<p style=\"top:481.5pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">r </span></b></p>\n<p style=\"top:494.9pt;left:180.5pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">5 </span></b></p>\n<p style=\"top:463.2pt;left:199.1pt;line-height:11.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">Test set  </span></b></p>\n<p style=\"top:463.0pt;left:272.7pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">234 </span></p>\n<p style=\"top:463.0pt;left:334.3pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">277 </span></p>\n<p style=\"top:463.0pt;left:386.4pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">511 </span></p>\n<p style=\"top:511.1pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:522.6pt;left:87.5pt;line-height:10.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:10.7pt\"> </span></b></p>\n<p style=\"top:534.9pt;left:87.5pt;line-height:10.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:10.7pt\"> </span></b></p>\n<p style=\"top:547.2pt;left:87.5pt;line-height:10.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:10.7pt\">4.2. Labeling training data </span></b></p>\n<p style=\"top:559.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:570.5pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">For labeling the training samples of each user using Tesseract we have taken help of a tool </span></p>\n<p style=\"top:581.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">named bbTesseract [13]. To generate the training files for a specific user, we need to prepare the </span></p>\n<p style=\"top:592.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">box files for each training images using the following command: </span></p>\n<p style=\"top:604.1pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:615.2pt;left:87.5pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tesseract fontfile.tif fontfile batch.nochop makebox </span></i></p>\n<p style=\"top:626.4pt;left:87.5pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></i></p>\n<p style=\"top:637.6pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">The box file is a text file that includes the characters in the training image, in order, one per </span></p>\n<p style=\"top:648.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">line, with the coordinates of the bounding box around the image. Incorrect labels in the training </span></p>\n<p style=\"top:659.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">set may be manually corrected using the bbTesseract Tool. </span></p>\n<p style=\"top:671.2pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Then we have to rename the boxfile fontfile.txt to fontfile.box. Fig. 2 shows a screenshot of the </span></p>\n<p style=\"top:682.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">bbTesseract tool. </span></p>\n<p style=\"top:693.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:05:24.726939",
            "file": "web_app/static/paper_tesseract_handwriting.pdf p.4",
            "content": "<div id=\"page0\" style=\"width:595.0pt;height:842.0pt\">\n<p style=\"top:71.9pt;left:181.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Proc. Int. Conf. on Information Technology and Business Intelligence (2009) 117-125 </span></p>\n<img style=\"position:absolute;transform:matrix(1.4718918,0,-0,1.2893913,186.56,154.7196)\" src=\"data:image/png;base64,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\npDA11HCD4f8BARxKAVXRJRsAAAAASUVORK5CYII=\">\n<p style=\"top:305.7pt;left:414.3pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></b></p>\n<p style=\"top:314.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:326.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Fig.2. A sample screenshot of a segmented training page using the bbTesseract tool </span></p>\n<p style=\"top:337.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:348.5pt;left:87.5pt;line-height:10.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:10.7pt\">4.3. Training the data using Tesseract OCR engine </span></b></p>\n<p style=\"top:360.6pt;left:99.4pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></b></p>\n<p style=\"top:371.8pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">For training a new language set for any user, we have to put in the effort to get one good box </span></p>\n<p style=\"top:383.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">file for a handwritten document page, run the rest of the training process, discussed below, to </span></p>\n<p style=\"top:394.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">create a new language set. Then use Tesseract again using the newly created language set to </span></p>\n<p style=\"top:405.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">label the rest of the box files corresponding to the remaining training images using the process </span></p>\n<p style=\"top:416.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">discussed in section 4.2.  </span></p>\n<p style=\"top:427.7pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">For each of our training image, boxfile pairs, run Tesseract in training mode using the following </span></p>\n<p style=\"top:438.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">command:  </span></p>\n<p style=\"top:450.1pt;left:99.4pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tesseract fontfile.tif junk nobatch box.train </span></i></p>\n<p style=\"top:461.3pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">The output of this step is fontfile.tr which contains the features of each character of the training </span></p>\n<p style=\"top:472.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">page. The character shape features can be clustered using the mftraining and cntraining </span></p>\n<p style=\"top:483.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">programs:  </span></p>\n<p style=\"top:494.8pt;left:99.4pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">mftraining fontfile_1.tr fontfile_2.tr ... </span></i></p>\n<p style=\"top:506.0pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">This will output three data files: inttemp , pffmtable and  Microfeat, and the following command:  </span></p>\n<p style=\"top:517.1pt;left:99.4pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">cntraining fontfile_1.tr fontfile_2.tr ... </span></i></p>\n<p style=\"top:528.3pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">This will output the normproto data file. Now, to generate the unicharset data file,  </span></p>\n<p style=\"top:539.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">unicharset_extractor program  is  used as follows:  </span></p>\n<p style=\"top:550.7pt;left:87.5pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">unicharset_extractor fontfile_1.box fontfile_2.box ... </span></i></p>\n<p style=\"top:561.8pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract uses 3 dictionary files for each language. Two of the files are coded as a Directed </span></p>\n<p style=\"top:573.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Acyclic Word Graph (DAWG), and the other is a plain UTF-8 text file. The wordlist is formatted as </span></p>\n<p style=\"top:584.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">a UTF-8 text file with one word per line. The corresponding commands are: </span></p>\n<p style=\"top:595.4pt;left:99.4pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">wordlist2dawg frequent_words_list freq-dawg </span></i></p>\n<p style=\"top:606.6pt;left:99.4pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">wordlist2dawg words_list word-dawg </span></i></p>\n<p style=\"top:617.8pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">The third dictionary file name is user-words and is usually empty. The final data file of </span></p>\n<p style=\"top:629.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract is DangAmbigs file. This file cannot be used to translate characters from one set to </span></p>\n<p style=\"top:640.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">another. The DangAmbigs file may be empty also. </span></p>\n<p style=\"top:651.4pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Now we have to collect all the 8 files and rename them with a lang. prefix, where lang is the 3-</span></p>\n<p style=\"top:662.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">letter code for our language and put them in our tessdata directory. Tesseract can then recognize </span></p>\n<p style=\"top:673.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">text in our language set using the command: </span></p>\n<p style=\"top:684.9pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:696.1pt;left:99.4pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">tesseract image.tif output -l lang </span></i></p>\n<p style=\"top:707.3pt;left:99.4pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></i></p>\n<p style=\"top:718.4pt;left:99.4pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></i></p>\n<p style=\"top:729.8pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:05:24.761931",
            "file": "web_app/static/paper_tesseract_handwriting.pdf p.5",
            "content": "<div id=\"page0\" style=\"width:595.0pt;height:842.0pt\">\n<p style=\"top:71.9pt;left:181.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Proc. Int. Conf. on Information Technology and Business Intelligence (2009) 117-125 </span></p>\n<p style=\"top:92.6pt;left:87.5pt;line-height:11.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">5. Experimental results </span></b></p>\n<p style=\"top:105.9pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:119.2pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">For conducting the current experiment, five user-specific language sets are generated using </span></p>\n<p style=\"top:130.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract open source OCR engine. The training and test patterns of each individual user are </span></p>\n<p style=\"top:141.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">spread over two types of datasets, as described in Sec. 4.1. The experiment is focused on testing </span></p>\n<p style=\"top:152.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">the segmentation and core recognition accuracy of Tesseract OCR engine on free flow </span></p>\n<p style=\"top:163.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">handwritten annotations written using digital pens by different users. The linguistic analysis </span></p>\n<p style=\"top:175.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">module of Tesseract, involving the language files freq-dawg, word-dawg, user-words and </span></p>\n<p style=\"top:186.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">DangAmbigs are not utilized in the current experiment. To evaluate the performance of the </span></p>\n<p style=\"top:197.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">present technique the following expression is developed. </span></p>\n<p style=\"top:208.6pt;left:103.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:219.8pt;left:103.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Recognition accuracy = (CB</span><span style=\"font-family:Arial,sans-serif;font-size:6.3pt\">tB</span><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> / (CB</span><span style=\"font-family:Arial,sans-serif;font-size:6.3pt\">m B</span><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">+ CB</span><span style=\"font-family:Arial,sans-serif;font-size:6.3pt\">sB</span><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">))*100 </span></p>\n<p style=\"top:231.0pt;left:103.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:242.2pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">where CB</span><span style=\"font-family:Arial,sans-serif;font-size:6.3pt\">tB</span><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> = the number of character segments producing true classification result and CB</span><span style=\"font-family:Arial,sans-serif;font-size:6.3pt\">mB</span><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:253.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">= the number of misclassified character segments and CB</span><span style=\"font-family:Arial,sans-serif;font-size:6.3pt\">s B</span><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">signifies the number of character </span></p>\n<p style=\"top:264.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract fails to segment, i.e., producing under segmentation. The rejected character/word </span></p>\n<p style=\"top:275.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">samples are excluded from computation of recognition accuracy of the designed system. </span></p>\n<p style=\"top:286.9pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Table 2(a-e) shows an analysis of successful classification (SC), misclassification (Misc), </span></p>\n<p style=\"top:298.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">segmentation failure (SF) and rejection (Rej) results on the test samples of the three users. Fig. 3 </span></p>\n<p style=\"top:309.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">shows a character wise distribution of success and failure accuracies on the overall test dataset. </span></p>\n<p style=\"top:320.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">As observed from the experimentation a significant proportion rejection cases evolve out of the </span></p>\n<p style=\"top:331.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">word segmentation failures. This is so because Tesseract is originally designed to recognize </span></p>\n<p style=\"top:342.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">printed document pages with uniformity in baseline and character/word spacings. Another source </span></p>\n<p style=\"top:354.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">of error is due to the internal segmentation of some of the characters. More specifically, the </span></p>\n<p style=\"top:365.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">character &apos;i&apos; often gets internally segmented into two parts, leading to high individual error rates.  </span></p>\n<p style=\"top:376.4pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:387.7pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:532.7pt;left:114.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">0</span></p>\n<p style=\"top:519.1pt;left:111.4pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">50</span></p>\n<p style=\"top:505.6pt;left:107.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">100</span></p>\n<p style=\"top:492.1pt;left:107.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">150</span></p>\n<p style=\"top:478.6pt;left:107.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">200</span></p>\n<p style=\"top:465.1pt;left:107.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">250</span></p>\n<p style=\"top:451.6pt;left:107.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">300</span></p>\n<p style=\"top:438.1pt;left:107.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">350</span></p>\n<p style=\"top:424.5pt;left:107.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">400</span></p>\n<p style=\"top:411.0pt;left:107.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">450</span></p>\n<p style=\"top:543.4pt;left:127.8pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">a</span></p>\n<p style=\"top:543.4pt;left:139.3pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">b</span></p>\n<p style=\"top:543.4pt;left:150.7pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">c</span></p>\n<p style=\"top:543.4pt;left:162.1pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">d</span></p>\n<p style=\"top:543.4pt;left:173.5pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">e</span></p>\n<p style=\"top:543.4pt;left:186.5pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">f</span></p>\n<p style=\"top:543.4pt;left:196.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">g</span></p>\n<p style=\"top:543.4pt;left:208.3pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">h</span></p>\n<p style=\"top:543.4pt;left:220.7pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">i</span></p>\n<p style=\"top:543.4pt;left:232.2pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">j</span></p>\n<p style=\"top:543.4pt;left:243.1pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">k</span></p>\n<p style=\"top:543.4pt;left:255.5pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">l</span></p>\n<p style=\"top:543.4pt;left:265.0pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">m</span></p>\n<p style=\"top:543.4pt;left:277.4pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">n</span></p>\n<p style=\"top:543.4pt;left:288.8pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">o</span></p>\n<p style=\"top:543.4pt;left:300.3pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">p</span></p>\n<p style=\"top:543.4pt;left:312.2pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">q</span></p>\n<p style=\"top:543.4pt;left:324.1pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">r</span></p>\n<p style=\"top:543.4pt;left:335.1pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">s</span></p>\n<p style=\"top:543.4pt;left:347.0pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">t</span></p>\n<p style=\"top:543.4pt;left:357.9pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">u</span></p>\n<p style=\"top:543.4pt;left:370.4pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">v</span></p>\n<p style=\"top:543.4pt;left:380.8pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">w</span></p>\n<p style=\"top:543.4pt;left:392.7pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">x</span></p>\n<p style=\"top:543.4pt;left:404.1pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">y</span></p>\n<p style=\"top:543.4pt;left:415.6pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">z</span></p>\n<p style=\"top:556.5pt;left:232.2pt;line-height:6.9pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">Labels of Test  Characters</span></b></p>\n<p style=\"top:488.9pt;left:97.1pt;line-height:6.9pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">Frequency</span></b></p>\n<p style=\"top:466.2pt;left:436.5pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">Success</span></p>\n<p style=\"top:478.0pt;left:436.5pt;line-height:6.9pt\"><span style=\"font-family:Arial,sans-serif;font-size:6.9pt\">Failure</span></p>\n<p style=\"top:567.8pt;left:468.3pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:576.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:587.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Fig. 3. Distribution of success and failure cases over the free flow test page. </span></p>\n<p style=\"top:599.3pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:612.7pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:626.0pt;left:148.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Table 2. Analysis of recognition performance of the developed system </span></p>\n<p style=\"top:637.2pt;left:297.6pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:648.4pt;left:188.2pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">(a) Recognition performance of User-1 test dataset </span></p>\n<p style=\"top:662.3pt;left:217.1pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></b></p>\n<p style=\"top:662.3pt;left:246.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Dataset-1 Dataset-2 Overall  </span></b></p>\n<p style=\"top:678.8pt;left:217.1pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SC </span></b></p>\n<p style=\"top:678.7pt;left:246.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">95.42 </span></p>\n<p style=\"top:678.7pt;left:294.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">83.2 </span></p>\n<p style=\"top:678.7pt;left:341.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">87.92 </span></p>\n<p style=\"top:695.3pt;left:217.1pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Misc </span></b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">4.1 </span></p>\n<p style=\"top:695.3pt;left:294.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">16.19 </span></p>\n<p style=\"top:695.3pt;left:341.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">11.52 </span></p>\n<p style=\"top:711.9pt;left:217.1pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SF </span></b></p>\n<p style=\"top:711.8pt;left:246.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0.48 </span></p>\n<p style=\"top:711.8pt;left:294.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0.61 </span></p>\n<p style=\"top:711.8pt;left:341.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0.56 </span></p>\n<p style=\"top:728.5pt;left:217.1pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Rej </span></b></p>\n<p style=\"top:728.3pt;left:246.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">6.10 </span></p>\n<p style=\"top:728.3pt;left:294.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">4.34 </span></p>\n<p style=\"top:728.3pt;left:341.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">5.03 </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:05:24.834932",
            "file": "web_app/static/paper_tesseract_handwriting.pdf p.6",
            "content": "<div id=\"page0\" style=\"width:595.0pt;height:842.0pt\">\n<p style=\"top:71.9pt;left:181.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Proc. Int. Conf. on Information Technology and Business Intelligence (2009) 117-125 </span></p>\n<p style=\"top:92.5pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:105.9pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:119.3pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:132.6pt;left:188.2pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">(b) Recognition performance of User-2 test dataset </span></p>\n<p style=\"top:146.6pt;left:216.4pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></b></p>\n<p style=\"top:146.6pt;left:246.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Dataset-1 Dataset-2 Overall </span></b></p>\n<p style=\"top:163.1pt;left:216.4pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SC </span></b></p>\n<p style=\"top:163.0pt;left:246.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">91.62 </span></p>\n<p style=\"top:163.0pt;left:294.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">76.45 </span></p>\n<p style=\"top:163.0pt;left:341.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">81.53 </span></p>\n<p style=\"top:180.1pt;left:216.4pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Misc </span></b></p>\n<p style=\"top:179.9pt;left:246.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">8.38 </span></p>\n<p style=\"top:179.9pt;left:294.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">18.31 </span></p>\n<p style=\"top:179.9pt;left:341.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">15.00 </span></p>\n<p style=\"top:197.1pt;left:216.4pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SF </span></b></p>\n<p style=\"top:197.0pt;left:246.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0.00 </span></p>\n<p style=\"top:197.0pt;left:294.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">5.24 </span></p>\n<p style=\"top:197.0pt;left:341.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">3.47 </span></p>\n<p style=\"top:213.7pt;left:216.4pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Rej </span></b></p>\n<p style=\"top:213.6pt;left:246.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">26.07 </span></p>\n<p style=\"top:213.6pt;left:294.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">4.18 </span></p>\n<p style=\"top:213.6pt;left:341.3pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">12.82 </span></p>\n<p style=\"top:227.8pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:241.1pt;left:188.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">(c) Recognition performance of User-3 test dataset </span></p>\n<p style=\"top:254.9pt;left:216.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:254.9pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Dataset-1 Dataset-2 Overall  </span></p>\n<p style=\"top:271.5pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SC </span></b></p>\n<p style=\"top:271.4pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">96.78 </span></p>\n<p style=\"top:271.4pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">90.94 </span></p>\n<p style=\"top:271.4pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">92.88 </span></p>\n<p style=\"top:288.0pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Misc </span></b></p>\n<p style=\"top:287.9pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">3.22 </span></p>\n<p style=\"top:287.9pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">6.18 </span></p>\n<p style=\"top:287.9pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">5.19 </span></p>\n<p style=\"top:304.6pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SF </span></b></p>\n<p style=\"top:304.5pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0.00 </span></p>\n<p style=\"top:304.5pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">2.88 </span></p>\n<p style=\"top:304.5pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">1.93 </span></p>\n<p style=\"top:321.1pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Rej </span></b></p>\n<p style=\"top:321.0pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">8.97 </span></p>\n<p style=\"top:321.0pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0.00 </span></p>\n<p style=\"top:321.0pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">3.16 </span></p>\n<p style=\"top:335.2pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:348.5pt;left:188.2pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">(d) Recognition performance of User-4 test dataset </span></p>\n<p style=\"top:362.5pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></b></p>\n<p style=\"top:362.5pt;left:247.1pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Dataset-1 Dataset-2 Overall  </span></b></p>\n<p style=\"top:379.0pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SC </span></b></p>\n<p style=\"top:378.9pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">90.38 </span></p>\n<p style=\"top:378.9pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">85.49 </span></p>\n<p style=\"top:378.9pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">86.75 </span></p>\n<p style=\"top:395.5pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Misc </span></b></p>\n<p style=\"top:395.4pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">8.85 </span></p>\n<p style=\"top:395.4pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">7.32 </span></p>\n<p style=\"top:395.4pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">7.72 </span></p>\n<p style=\"top:412.0pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SF </span></b></p>\n<p style=\"top:411.9pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0.77 </span></p>\n<p style=\"top:411.9pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">7.19 </span></p>\n<p style=\"top:411.9pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">6.03 </span></p>\n<p style=\"top:428.6pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Rej </span></b></p>\n<p style=\"top:428.5pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:428.5pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:428.5pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:442.7pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:455.9pt;left:189.8pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">e) Recognition performance of User-5 test dataset </span></p>\n<p style=\"top:469.9pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></b></p>\n<p style=\"top:469.9pt;left:247.1pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Dataset-1 Dataset-2 Overall  </span></b></p>\n<p style=\"top:486.4pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SC </span></b></p>\n<p style=\"top:486.3pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">91.88 </span></p>\n<p style=\"top:486.3pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">89.89 </span></p>\n<p style=\"top:486.3pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">90.80 </span></p>\n<p style=\"top:503.0pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Misc </span></b></p>\n<p style=\"top:502.9pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">8.12 </span></p>\n<p style=\"top:502.9pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">10.11 </span></p>\n<p style=\"top:502.9pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">9.20 </span></p>\n<p style=\"top:519.5pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">SF </span></b></p>\n<p style=\"top:519.4pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:519.4pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:519.4pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:536.0pt;left:216.7pt;line-height:9.7pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">Rej </span></b></p>\n<p style=\"top:535.9pt;left:247.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:535.9pt;left:294.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:535.9pt;left:341.8pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">0 </span></p>\n<p style=\"top:549.8pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:561.1pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:572.3pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<img style=\"position:absolute;transform:matrix(1.16,0,-0,1.4789189,282.16,789.27969)\" src=\"data:image/png;base64,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\n8cm0AAAAAElFTkSuQmCC\">\n<img style=\"position:absolute;transform:matrix(.45691536,0,-0,.7294915,307.71998,772.43966)\" src=\"data:image/png;base64,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\nIyPjh+F/P3g5sLw1e7UAAAAASUVORK5CYII=\">\n<p style=\"top:609.4pt;left:450.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:618.4pt;left:312.7pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<img style=\"position:absolute;transform:matrix(1.2300918,0,-0,1.111579,285.76,847.1596)\" src=\"data:image/png;base64,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\n/X1IUQf3vG0AAAAASUVORK5CYII=\">\n<img style=\"position:absolute;transform:matrix(1.4229058,0,-0,1.2993939,442.11997,850.4796)\" src=\"data:image/png;base64,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\n+/+7xQvRw7Ip2G19nkepexX6DbW8zn0roEhOAAAAAElFTkSuQmCC\">\n<p style=\"top:658.1pt;left:437.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:669.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:669.8pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:669.8pt;left:122.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:669.8pt;left:156.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:669.8pt;left:190.9pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:681.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:681.1pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:681.1pt;left:122.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:681.1pt;left:156.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Fig. 4. Some of the successfully segmented and recognized word images. </span></p>\n<p style=\"top:692.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:703.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:05:24.975931",
            "file": "web_app/static/paper_tesseract_handwriting.pdf p.7",
            "content": "<div id=\"page0\" style=\"width:595.0pt;height:842.0pt\">\n<p style=\"top:71.9pt;left:181.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Proc. Int. Conf. on Information Technology and Business Intelligence (2009) 117-125 </span></p>\n<p style=\"top:119.1pt;left:194.6pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\">(a) </span></p>\n<p style=\"top:127.3pt;left:302.8pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\">(b) </span></p>\n<p style=\"top:143.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:143.1pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:143.1pt;left:122.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:143.1pt;left:156.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:143.1pt;left:190.9pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:143.1pt;left:225.4pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:154.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:154.4pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:154.4pt;left:122.0pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:154.4pt;left:156.5pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:154.4pt;left:190.9pt;line-height:9.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:154.4pt;left:225.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Fig. 5. Some of the misclassified word images </span></p>\n<p style=\"top:165.5pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:176.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:176.8pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:176.8pt;left:122.0pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:176.8pt;left:156.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:176.8pt;left:190.9pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:176.8pt;left:225.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">(a) Recognition error in the 3</span><sup><span style=\"font-family:Arial,sans-serif;font-size:6.3pt\">rd</span></sup><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> character </span></p>\n<p style=\"top:188.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:188.0pt;left:105.1pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:188.0pt;left:122.0pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:188.0pt;left:156.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:188.0pt;left:190.9pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> </span></p>\n<p style=\"top:188.0pt;left:225.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">(b) Internal segmentation in the 8</span><sup><span style=\"font-family:Arial,sans-serif;font-size:6.3pt\">th</span></sup><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> character </span></p>\n<p style=\"top:199.3pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:212.5pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">As shown in Table 2(a-e), the overall character-level recognition accuracy of the developed </span></p>\n<p style=\"top:223.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">system is around 87.98%. The overall character misclassification rate is observed as around </span></p>\n<p style=\"top:234.9pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">9.73%. Segmentation failures in the document pages account for around 2.29% error cases. The </span></p>\n<p style=\"top:246.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">reason behind high segmentation failure is due to the over-segmentation of some of the </span></p>\n<p style=\"top:257.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">constituent characters like &#x2018;i&#x2019;, &apos;j&apos; and also due to under-segmentation of cursive words in the </span></p>\n<p style=\"top:268.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">document pages. The designed system rejects around 9.24% characters in the test dataset. This </span></p>\n<p style=\"top:279.6pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">is mainly due to the presence of multi-skewed handwritten text lines in the test documents. </span></p>\n<p style=\"top:290.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Completely cursive words were also rejected completely in many cases during the </span></p>\n<p style=\"top:302.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">experimentation. Some of the sample word images successfully segmented and recognized by </span></p>\n<p style=\"top:313.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Tesseract are shown in Fig. 4. Fig. 5(a-b) shows some of the word images with erroneous </span></p>\n<p style=\"top:324.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">segmentation and recognition results. </span></p>\n<p style=\"top:335.5pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">A major drawback of the current system is its failure to avoid over-segmentation in some of the </span></p>\n<p style=\"top:346.7pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">characters. Also the system fails to segment cursive words in many cases leading to under-</span></p>\n<p style=\"top:358.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">segmentation and rejection. The recognition performance of the designed system may further be </span></p>\n<p style=\"top:369.1pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">improved by incorporating more training samples for each user and inclusion of word-level </span></p>\n<p style=\"top:380.3pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">dictionary matching techniques. </span></p>\n<p style=\"top:391.5pt;left:99.4pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">Despite these limitations, the designed recognition engine is successfully integrated with the </span></p>\n<p style=\"top:402.6pt;left:87.5pt;line-height:9.7pt\"><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT </span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">system for online interpretation of handwritten textual annotations. The word-level recognition </span></p>\n<p style=\"top:413.8pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">time of the OCR engine, as observed on reasonably powered computer hardware, is also found </span></p>\n<p style=\"top:425.0pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">to be satisfactory. In a nutshell, the current work effectively customizes an open source OCR </span></p>\n<p style=\"top:436.2pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">engine for segmentation and recognition of handwritten textual annotations of multiple users </span></p>\n<p style=\"top:447.4pt;left:87.5pt;line-height:9.7pt\"><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">within the designed </span><i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\">iJIT</span></i><span style=\"font-family:Arial,sans-serif;font-size:9.7pt\"> system. </span></p>\n<p style=\"top:458.7pt;left:99.4pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:472.3pt;left:87.5pt;line-height:11.7pt\"><b><span style=\"font-family:Arial,sans-serif;font-size:11.7pt\">6. References </span></b></p>\n<p style=\"top:485.5pt;left:87.5pt;line-height:11.7pt\"><span style=\"font-family:Times New Roman,serif;font-size:11.7pt\"> </span></p>\n<p style=\"top:498.6pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Times New Roman,serif;font-size:8.8pt\">[</span><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">1] www.anoto.com </span></p>\n<p style=\"top:508.8pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[2]  Bertrand Co&#xfc;asnon &#xb7; Jean Camillerapp &#xb7; Ivan Leplumey, &#x201c;Access by content to handwritten archive </span></p>\n<p style=\"top:518.8pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">documents: generic document recognition method and platform for annotations&#x201d;, IJDAR (2007) 9: 223&#x2013;</span></p>\n<p style=\"top:528.9pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">242. </span></p>\n<p style=\"top:539.0pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[3]  Matthew Ma, Chi Zhang and Patrick Wang, &#x201c;Studies of Radical Model for Retrieval of Cursive Chinese </span></p>\n<p style=\"top:549.1pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Handwritten Annotations&#x201d;, SSPR&amp;SPR 2000, LNCS 1876, pp. 407-416, 2000. </span></p>\n<p style=\"top:559.1pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[4]  Sargur Srihari, Anantharaman Ganesh, Catalin Tomai, Yong-Chul Shin, and Chen Huang, &#x201c;Information </span></p>\n<p style=\"top:569.2pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Retrieval System for Handwritten Documents&#x201d;, DAS 2004, LNCS 3163, pp. 298&#x2013;309, 2004. </span></p>\n<p style=\"top:579.3pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[5] S. Basu, K. Konishi, N. Furukawa, H, Ikeda, &#x201c;A novel scheme for retrieval of handwritten textual </span></p>\n<p style=\"top:589.3pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">annotations for information Just In Time (iJIT)&#x201d;, proceedings (CD) of IEEE Region 10 Conference </span></p>\n<p style=\"top:599.4pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">(TENCON) -2008. </span></p>\n<p style=\"top:609.4pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[6]  David Doermann, &#x201c;The Indexing and Retrieval of Document Images: A Survey&#x201d;, Computer Vision and </span></p>\n<p style=\"top:619.5pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Image Understanding archive Volume 70 , Issue 3. </span></p>\n<p style=\"top:629.5pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[7] R.M. Bozinovic and S.N. Srihari, &#x201c;Off-line Cursive Script Word Recognition&#x201d;, IEEE Trans. Pattern </span></p>\n<p style=\"top:639.6pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Analysis and Machine Intelligence, vol. 11,pp 68-83, 1989. </span></p>\n<p style=\"top:649.6pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[8] B. B. Chaudhuri and U. Pal, &#x201c;A Complete Printed Bangla OCR System&#x201d;, Pattern Recognition, vol. 31, </span></p>\n<p style=\"top:659.8pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">No. 5. pp. 531-549, 1998. </span></p>\n<p style=\"top:669.8pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[9] S. Basu, C. Chawdhuri, M. Kundu, M. Nasipuri, D. K. Basu, &#x201c;A Two-pass Approach to Pattern </span></p>\n<p style=\"top:679.9pt;left:105.1pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">Classification&#x201d;, N.R. Pal et.al. (Eds.), ICONIP, LNCS 3316, pp. 781-786.  </span></p>\n<p style=\"top:689.9pt;left:87.5pt;line-height:8.8pt\"><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">[10] http://code.google.com/p/tesseract-ocr</span><i><span style=\"font-family:Arial,sans-serif;font-size:8.8pt\">  </span></i></p>\n<img style=\"position:absolute;transform:matrix(.50885239,0,-0,.7476363,320.75999,119.63963)\" src=\"data:image/png;base64,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\nNa2G3ohi/H882jAX1UxU3wAAAABJRU5ErkJggg==\">\n<img style=\"position:absolute;transform:matrix(.7926011,0,-0,.7958974,242.07999,122.199649)\" src=\"data:image/png;base64,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\">\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:06:47.234634",
            "file": "web_app/static/sample_0.pdf p.0",
            "content": "<div id=\"page0\" style=\"width:595.3pt;height:841.9pt\">\n<p style=\"top:71.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World </span></p>\n<p style=\"top:94.1pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World1 </span></p>\n<p style=\"top:116.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:139.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World2 </span></p>\n<p style=\"top:162.7pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:185.5pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:208.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World3 </span></p>\n<p style=\"top:231.1pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:253.9pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n<p style=\"top:276.7pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World4 </span></p>\n<p style=\"top:299.5pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World5 </span></p>\n<p style=\"top:322.3pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\">Hello World6 </span></p>\n<p style=\"top:345.1pt;left:70.8pt;line-height:11.0pt\"><span style=\"font-family:BradleyHandITC,sans-serif;font-size:11.0pt\"> </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:08:30.674222",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "<div id=\"page0\" style=\"width:612.0pt;height:792.0pt\">\n<p style=\"top:97.8pt;left:177.8pt;line-height:13.9pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:13.9pt\">An Overview of the Tesseract OCR Engine </span></b></p>\n<p style=\"top:113.3pt;left:306.0pt;line-height:12.0pt\"><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\"> </span></p>\n<p style=\"top:127.2pt;left:306.0pt;line-height:12.0pt\"><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\"> </span></p>\n<p style=\"top:140.9pt;left:280.6pt;line-height:12.0pt\"><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">Ray Smith  </span></p>\n<p style=\"top:154.8pt;left:277.4pt;line-height:12.0pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">Google Inc. </span></i></p>\n<p style=\"top:168.5pt;left:247.0pt;line-height:12.0pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">theraysmith@gmail.com </span></i></p>\n<p style=\"top:182.4pt;left:72.0pt;line-height:12.0pt\"><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\"> </span></p>\n<p style=\"top:196.3pt;left:161.0pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">Abstract </span></b></p>\n<p style=\"top:209.6pt;left:72.0pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></i></p>\n<p style=\"top:220.9pt;left:84.2pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The Tesseract OCR engine, as was the HP Research </span></i></p>\n<p style=\"top:232.4pt;left:72.0pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Prototype in the UNLV Fourth Annual Test of OCR </span></i></p>\n<p style=\"top:243.9pt;left:72.0pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Accuracy[1], is described in a comprehensive </span></i></p>\n<p style=\"top:255.5pt;left:72.0pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">overview. Emphasis is placed on aspects that are novel </span></i></p>\n<p style=\"top:267.0pt;left:72.0pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">or at least unusual in an OCR engine, including in </span></i></p>\n<p style=\"top:278.5pt;left:72.0pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">particular the line finding, features/classification </span></i></p>\n<p style=\"top:290.0pt;left:72.0pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">methods, and the adaptive classifier. </span></i></p>\n<p style=\"top:301.5pt;left:84.2pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">  </span></i></p>\n<p style=\"top:313.1pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:325.2pt;left:72.0pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">1. Introduction &#x2013; Motivation and History </span></b></p>\n<p style=\"top:338.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:349.8pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract is an open-source OCR engine that was </span></p>\n<p style=\"top:361.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">developed at HP between 1984 and 1994. Like a super-</span></p>\n<p style=\"top:372.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">nova, it appeared from nowhere for the 1995 UNLV </span></p>\n<p style=\"top:384.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Annual Test of OCR Accuracy [1], shone brightly with </span></p>\n<p style=\"top:395.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">its results, and then vanished back under the same </span></p>\n<p style=\"top:407.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">cloak of secrecy under which it had been developed. </span></p>\n<p style=\"top:418.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Now for the first time, details of the architecture and </span></p>\n<p style=\"top:430.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">algorithms can be revealed. </span></p>\n<p style=\"top:441.7pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract began as a PhD research project [2] in HP </span></p>\n<p style=\"top:453.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Labs, Bristol, and gained momentum as a possible </span></p>\n<p style=\"top:464.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">software and/or hardware add-on for HP&#x2019;s line of </span></p>\n<p style=\"top:476.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">flatbed scanners. Motivation was provided by the fact </span></p>\n<p style=\"top:487.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">that the commercial OCR engines of the day were in </span></p>\n<p style=\"top:499.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">their infancy, and failed miserably on anything but the </span></p>\n<p style=\"top:510.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">best quality print. </span></p>\n<p style=\"top:522.3pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">After a joint project between HP Labs Bristol, and </span></p>\n<p style=\"top:533.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">HP&#x2019;s scanner division in Colorado, Tesseract had a </span></p>\n<p style=\"top:545.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">significant lead in accuracy over the commercial </span></p>\n<p style=\"top:556.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">engines, but did not become a product. The next stage </span></p>\n<p style=\"top:568.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">of its development was back in HP Labs Bristol as an </span></p>\n<p style=\"top:579.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">investigation </span></p>\n<p style=\"top:579.7pt;left:134.7pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">of </span></p>\n<p style=\"top:579.7pt;left:153.6pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">OCR </span></p>\n<p style=\"top:579.7pt;left:185.1pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">for </span></p>\n<p style=\"top:579.7pt;left:207.6pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">compression. </span></p>\n<p style=\"top:579.7pt;left:271.9pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Work </span></p>\n<p style=\"top:591.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">concentrated more on improving rejection efficiency </span></p>\n<p style=\"top:602.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">than on base-level accuracy. At the end of this project, </span></p>\n<p style=\"top:614.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">at the end of 1994, development ceased entirely. The </span></p>\n<p style=\"top:625.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">engine was sent to UNLV for the 1995 Annual Test of </span></p>\n<p style=\"top:637.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">OCR Accuracy[1], where it proved its worth against </span></p>\n<p style=\"top:648.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the commercial engines of the time. In late 2005, HP </span></p>\n<p style=\"top:660.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">released Tesseract for open source. It is now available </span></p>\n<p style=\"top:671.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">at http://code.google.com/p/tesseract-ocr. </span></p>\n<p style=\"top:683.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:196.3pt;left:317.5pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">2. Architecture </span></b></p>\n<p style=\"top:209.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:220.9pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Since HP had independently-developed page layout </span></p>\n<p style=\"top:232.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">analysis technology that was used in products, (and </span></p>\n<p style=\"top:243.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">therefore not released for open-source) Tesseract never </span></p>\n<p style=\"top:255.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">needed its own page layout analysis. Tesseract </span></p>\n<p style=\"top:267.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">therefore assumes that its input is a binary image with </span></p>\n<p style=\"top:278.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">optional polygonal text regions defined. </span></p>\n<p style=\"top:290.0pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Processing follows a traditional step-by-step </span></p>\n<p style=\"top:301.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">pipeline, but some of the stages were unusual in their </span></p>\n<p style=\"top:313.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">day, and possibly remain so even now. The first step is </span></p>\n<p style=\"top:324.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">a connected component analysis in which outlines of </span></p>\n<p style=\"top:336.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the components are stored. This was a computationally </span></p>\n<p style=\"top:347.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">expensive design decision at the time, but had a </span></p>\n<p style=\"top:358.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">significant advantage: by inspection of the nesting of </span></p>\n<p style=\"top:370.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">outlines, and the number of child and grandchild </span></p>\n<p style=\"top:381.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">outlines, it is simple to detect inverse text and </span></p>\n<p style=\"top:393.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">recognize it as easily as black-on-white text. Tesseract </span></p>\n<p style=\"top:405.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">was probably the first OCR engine able to handle </span></p>\n<p style=\"top:416.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">white-on-black text so trivially. At this stage, outlines </span></p>\n<p style=\"top:428.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">are gathered together, purely by nesting, into </span><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Blobs</span></i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">. </span></p>\n<p style=\"top:439.5pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Blobs are organized into text lines, and the lines and </span></p>\n<p style=\"top:451.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">regions are analyzed for fixed pitch or proportional </span></p>\n<p style=\"top:462.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">text. Text lines are broken into words differently </span></p>\n<p style=\"top:474.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">according to the kind of character spacing. Fixed pitch </span></p>\n<p style=\"top:485.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">text is chopped immediately by character cells. </span></p>\n<p style=\"top:496.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Proportional text is broken into words using definite </span></p>\n<p style=\"top:508.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">spaces and fuzzy spaces. </span></p>\n<p style=\"top:519.9pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Recognition then proceeds as a two-pass process. In </span></p>\n<p style=\"top:531.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the first pass, an attempt is made to recognize each </span></p>\n<p style=\"top:543.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">word in turn. Each word that is satisfactory is passed to </span></p>\n<p style=\"top:554.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">an adaptive classifier as training data. The adaptive </span></p>\n<p style=\"top:566.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">classifier then gets a chance to more accurately </span></p>\n<p style=\"top:577.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">recognize text lower down the page. </span></p>\n<p style=\"top:589.1pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Since the adaptive classifier may have learned </span></p>\n<p style=\"top:600.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">something useful too late to make a contribution near </span></p>\n<p style=\"top:611.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the top of the page, a second pass is run over the page, </span></p>\n<p style=\"top:623.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">in which words that were not recognized well enough </span></p>\n<p style=\"top:634.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">are recognized again. </span></p>\n<p style=\"top:646.4pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">A final phase resolves fuzzy spaces, and checks </span></p>\n<p style=\"top:657.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">alternative hypotheses for the x-height to locate small-</span></p>\n<p style=\"top:669.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">cap text. </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:08:30.708513",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "<div id=\"page0\" style=\"width:612.0pt;height:792.0pt\">\n<p style=\"top:73.4pt;left:72.0pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">3. Line and Word Finding </span></b></p>\n<p style=\"top:86.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:98.4pt;left:72.0pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">3.1. Line Finding </span></b></p>\n<p style=\"top:110.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:122.3pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The line finding algorithm is one of the few parts of </span></p>\n<p style=\"top:133.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract that has previously been published [3]. The </span></p>\n<p style=\"top:145.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">line finding algorithm is designed so that a skewed </span></p>\n<p style=\"top:156.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">page can be recognized without having to de-skew, </span></p>\n<p style=\"top:168.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">thus saving loss of image quality. The key parts of the </span></p>\n<p style=\"top:179.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">process are blob filtering and line construction. </span></p>\n<p style=\"top:191.1pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Assuming that page layout analysis has already </span></p>\n<p style=\"top:202.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">provided text regions of a roughly uniform text size, a </span></p>\n<p style=\"top:214.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">simple percentile height filter removes drop-caps and </span></p>\n<p style=\"top:225.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">vertically touching characters. The median height </span></p>\n<p style=\"top:237.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">approximates the text size in the region, so it is safe to </span></p>\n<p style=\"top:248.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">filter out blobs that are smaller than some fraction of </span></p>\n<p style=\"top:260.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the median height, being most likely punctuation, </span></p>\n<p style=\"top:271.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">diacritical marks and noise. </span></p>\n<p style=\"top:283.3pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The filtered blobs are more likely to fit a model of </span></p>\n<p style=\"top:294.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">non-overlapping, parallel, but sloping lines. Sorting </span></p>\n<p style=\"top:306.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">and processing the blobs by x-coordinate makes it </span></p>\n<p style=\"top:317.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">possible to assign blobs to a unique text line, while </span></p>\n<p style=\"top:329.1pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">tracking the slope across the page, with greatly reduced </span></p>\n<p style=\"top:340.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">danger of assigning to an incorrect text line in the </span></p>\n<p style=\"top:352.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">presence of skew. Once the filtered blobs have been </span></p>\n<p style=\"top:363.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">assigned to lines, a least median of squares fit [4] is </span></p>\n<p style=\"top:375.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">used to estimate the baselines, and the filtered-out </span></p>\n<p style=\"top:386.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">blobs are fitted back into the appropriate lines. </span></p>\n<p style=\"top:398.3pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The final step of the line creation process merges </span></p>\n<p style=\"top:409.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">blobs that overlap by at least half horizontally, putting </span></p>\n<p style=\"top:421.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">diacritical marks together with the correct base and </span></p>\n<p style=\"top:432.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">correctly associating parts of some broken characters. </span></p>\n<p style=\"top:444.3pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:456.0pt;left:72.0pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">3.2. Baseline Fitting </span></b></p>\n<p style=\"top:468.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:479.9pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Once the text lines have been found, the baselines </span></p>\n<p style=\"top:491.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">are fitted more precisely using a quadratic spline. This </span></p>\n<p style=\"top:502.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">was another first for an OCR system, and enabled </span></p>\n<p style=\"top:514.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract to handle pages with curved baselines [5], </span></p>\n<p style=\"top:525.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">which are a common artifact in scanning, and not just </span></p>\n<p style=\"top:537.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">at book bindings. </span></p>\n<p style=\"top:549.0pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The baselines are fitted by partitioning the blobs </span></p>\n<p style=\"top:560.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">into groups with a reasonably continuous displacement </span></p>\n<p style=\"top:571.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">for the original straight baseline. A quadratic spline is </span></p>\n<p style=\"top:583.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">fitted to the most populous partition, (assumed to be </span></p>\n<p style=\"top:594.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the baseline) by a least squares fit. The quadratic spline </span></p>\n<p style=\"top:606.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">has the advantage that this calculation is reasonably </span></p>\n<p style=\"top:617.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">stable, but the disadvantage that discontinuities can </span></p>\n<p style=\"top:629.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">arise when multiple spline segments are required. A </span></p>\n<p style=\"top:640.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">more traditional cubic spline [6] might work better. </span></p>\n<p style=\"top:670.7pt;left:297.1pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:680.0pt;left:74.6pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">Fig. 1. An example of a curved fitted baseline. </span></b></p>\n<p style=\"top:72.8pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Fig.1 shows an example of a line of text with a </span></p>\n<p style=\"top:84.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">fitted baseline, descender line, meanline and ascender </span></p>\n<p style=\"top:95.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">line. All these lines are &#x201c;parallel&#x201d; (the y separation is a </span></p>\n<p style=\"top:107.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">constant over the entire length) and slightly curved. </span></p>\n<p style=\"top:118.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The ascender line is cyan (prints as light gray) and the </span></p>\n<p style=\"top:130.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">black line above it is actually straight. Close inspection </span></p>\n<p style=\"top:141.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">shows that the cyan/gray line is curved relative to the </span></p>\n<p style=\"top:153.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">straight black line above it. </span></p>\n<p style=\"top:164.7pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:176.7pt;left:317.5pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">3.3. Fixed Pitch Detection and Chopping </span></b></p>\n<p style=\"top:189.0pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:200.5pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract tests the text lines to determine whether </span></p>\n<p style=\"top:212.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">they are fixed pitch. Where it finds fixed pitch text, </span></p>\n<p style=\"top:223.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract chops the words into characters using the </span></p>\n<p style=\"top:235.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">pitch, and disables the chopper and associator on these </span></p>\n<p style=\"top:246.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">words for the word recognition step. Fig. 2 shows a </span></p>\n<p style=\"top:257.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">typical example of a fixed-pitch word. </span></p>\n<img style=\"position:absolute;transform:matrix(.6358799,0,-0,.63666668,338.52003,340.64)\" src=\"data:image/png;base64,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\nBrJCkA+CrHAQq/8BKHsF9hwoehIAAAAASUVORK5CYII=\">\n<p style=\"top:306.3pt;left:539.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:315.7pt;left:345.6pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">Fig. 2. A fixed-pitch chopped word. </span></b></p>\n<p style=\"top:327.2pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:339.2pt;left:317.5pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">3.4. Proportional Word Finding </span></b></p>\n<p style=\"top:351.2pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:362.7pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Non-fixed-pitch or proportional text spacing is a </span></p>\n<p style=\"top:374.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">highly non-trivial task. Fig. 3 illustrates some typical </span></p>\n<p style=\"top:385.8pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">problems. The gap between the tens and units of </span></p>\n<p style=\"top:397.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">&#x2018;11.9%&#x2019; is a similar size to the general space, and is </span></p>\n<p style=\"top:408.8pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">certainly larger than the kerned space between &#x2018;erated&#x2019; </span></p>\n<p style=\"top:420.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">and &#x2018;junk&#x2019;. There is no horizontal gap at all between </span></p>\n<p style=\"top:431.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the bounding boxes of &#x2018;of&#x2019; and &#x2018;financial&#x2019;. Tesseract </span></p>\n<p style=\"top:443.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">solves most of these problems by measuring gaps in a </span></p>\n<p style=\"top:454.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">limited vertical range between the baseline and mean </span></p>\n<p style=\"top:466.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">line. Spaces that are close to the threshold at this stage </span></p>\n<p style=\"top:477.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">are made fuzzy, so that a final decision can be made </span></p>\n<p style=\"top:489.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">after word recognition. </span></p>\n<p style=\"top:527.9pt;left:549.6pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:550.9pt;left:535.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:560.5pt;left:344.6pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">Fig. 3. Some difficult word spacing. </span></b></p>\n<p style=\"top:572.4pt;left:317.5pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\"> </span></b></p>\n<p style=\"top:586.3pt;left:317.5pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">4. Word Recognition </span></b></p>\n<p style=\"top:599.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:610.9pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Part of the recognition process for any character </span></p>\n<p style=\"top:622.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">recognition engine is to identify how a word should be </span></p>\n<p style=\"top:633.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">segmented into characters. The initial segmentation </span></p>\n<p style=\"top:645.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">output from line finding is classified first. The rest of </span></p>\n<p style=\"top:657.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the word recognition step applies only to non-fixed-</span></p>\n<p style=\"top:668.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">pitch text.  </span></p>\n<p style=\"top:680.0pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<img style=\"position:absolute;transform:matrix(.49565218,0,-0,.49548389,300.48005,699.2401)\" src=\"data:image/png;base64,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\nY4wxZit+8RhjjNmKXzzGGGO28h+Y+d3xCHuvhAAAAABJRU5ErkJggg==\">\n<img style=\"position:absolute;transform:matrix(.50051286,0,-0,.5,294.08003,642.56008)\" src=\"data:image/png;base64,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\">\n<img style=\"position:absolute;transform:matrix(.34902329,0,-0,.36480005,-183.92,837.04006)\" src=\"data:image/png;base64,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\nSyEAAABeXAoBAADw4lIIAACA//kvaHYLGq7C47MAAAAASUVORK5CYII=\">\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:08:30.740950",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "<div id=\"page0\" style=\"width:612.0pt;height:792.0pt\">\n<p style=\"top:73.2pt;left:72.0pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">4.1 Chopping Joined Characters </span></b></p>\n<p style=\"top:85.5pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:97.1pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">While the result from a word (see section 6) is </span></p>\n<p style=\"top:108.6pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">unsatisfactory, Tesseract attempts to improve the result </span></p>\n<p style=\"top:119.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">by chopping the blob with worst confidence from the </span></p>\n<p style=\"top:131.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">character classifier. Candidate chop points are found </span></p>\n<p style=\"top:142.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">from concave vertices of a polygonal approximation </span></p>\n<p style=\"top:154.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">[2] of the outline, and may have either another concave </span></p>\n<p style=\"top:165.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">vertex opposite, or a line segment. It may take up to 3 </span></p>\n<p style=\"top:177.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">pairs of chop points to successfully separate joined </span></p>\n<p style=\"top:189.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">characters from the ASCII set. </span></p>\n<img style=\"position:absolute;transform:matrix(.7490909,0,-0,.7487582,46.319993,247.52002)\" src=\"data:image/png;base64,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\nAITnFBQ+p5XYAAAAAElFTkSuQmCC\">\n<p style=\"top:277.5pt;left:294.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:286.9pt;left:88.3pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">Fig. 4. Candidate chop points and chop. </span></b></p>\n<p style=\"top:298.9pt;left:183.1pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\"> </span></b></p>\n<p style=\"top:310.2pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Fig. 4 shows a set of candidate chop points with </span></p>\n<p style=\"top:321.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">arrows and the selected chop as a line across the </span></p>\n<p style=\"top:333.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">outline where the &#x2018;r&#x2019; touches the &#x2018;m&#x2019;. </span></p>\n<p style=\"top:344.7pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Chops are executed in priority order. Any chop that </span></p>\n<p style=\"top:356.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">fails to improve the confidence of the result is undone, </span></p>\n<p style=\"top:367.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">but not completely discarded so that the chop can be </span></p>\n<p style=\"top:379.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">re-used later by the associator if needed. </span></p>\n<p style=\"top:390.8pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:402.5pt;left:72.0pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">4.2. Associating Broken Characters </span></b></p>\n<p style=\"top:414.8pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:426.3pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">When the potential chops have been exhausted, if </span></p>\n<p style=\"top:437.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the word is still not good enough, it is given to the </span></p>\n<p style=\"top:449.4pt;left:72.0pt;line-height:10.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">associator</span></i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">. The associator makes an A* (best first) </span></p>\n<p style=\"top:460.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">search of the segmentation graph of possible </span></p>\n<p style=\"top:472.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">combinations of the maximally chopped blobs into </span></p>\n<p style=\"top:483.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">candidate characters. It does this without actually </span></p>\n<p style=\"top:495.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">building the segmentation graph, but instead maintains </span></p>\n<p style=\"top:506.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">a hash table of visited states. The A* search proceeds </span></p>\n<p style=\"top:518.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">by pulling candidate new states from a priority queue </span></p>\n<p style=\"top:529.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">and evaluating them by classifying unclassified </span></p>\n<p style=\"top:541.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">combinations of fragments. </span></p>\n<p style=\"top:552.8pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">It may be argued that this fully-chop-then-associate </span></p>\n<p style=\"top:564.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">approach is at best inefficient, at worst liable to miss </span></p>\n<p style=\"top:575.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">important chops, and that may well be the case. The </span></p>\n<p style=\"top:587.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">advantage is that the chop-then-associate scheme </span></p>\n<p style=\"top:598.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">simplifies the data structures that would be required to </span></p>\n<p style=\"top:610.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">maintain the full segmentation graph. </span></p>\n<img style=\"position:absolute;transform:matrix(.7270588,0,-0,.7262609,40.319993,812.91989)\" src=\"data:image/png;base64,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\nrkJggg==\">\n<p style=\"top:675.7pt;left:294.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:685.1pt;left:102.7pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">Fig. 5. An easily recognized word. </span></b></p>\n<p style=\"top:72.8pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">When the A* segmentation search was first </span></p>\n<p style=\"top:84.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">implemented in about 1989, Tesseract&#x2019;s accuracy on </span></p>\n<p style=\"top:95.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">broken characters was well ahead of the commercial </span></p>\n<p style=\"top:107.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">engines of the day. Fig. 5 is a typical example. An </span></p>\n<p style=\"top:118.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">essential part of that success was the character </span></p>\n<p style=\"top:130.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">classifier that could easily recognize broken characters. </span></p>\n<p style=\"top:141.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:153.8pt;left:317.5pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">5. Static Character Classifier </span></b></p>\n<p style=\"top:167.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:179.1pt;left:317.5pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">5.1. Features </span></b></p>\n<p style=\"top:191.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:202.7pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">An early version of Tesseract used topological </span></p>\n<p style=\"top:214.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">features developed from the work of Shillman et. al. </span></p>\n<p style=\"top:225.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">[7-8] Though nicely independent of font and size, these </span></p>\n<p style=\"top:237.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">features are not robust to the problems found in real-</span></p>\n<p style=\"top:248.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">life images, as Bokser [9] describes. An intermediate </span></p>\n<p style=\"top:260.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">idea involved the use of segments of the polygonal </span></p>\n<p style=\"top:271.8pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">approximation as features, but this approach is also not </span></p>\n<p style=\"top:283.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">robust to damaged characters. For example, in Fig. </span></p>\n<p style=\"top:294.8pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">6(a), the right side of the shaft is in two main pieces, </span></p>\n<p style=\"top:306.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">but in Fig. 6(b) there is just a single piece. </span></p>\n<img style=\"position:absolute;transform:matrix(.7408,0,-0,.7410526,371.52003,406.12)\" src=\"data:image/png;base64,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\naiGN3sHZCwAAAABJRU5ErkJggg==\">\n<p style=\"top:420.6pt;left:539.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:429.9pt;left:336.5pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">Fig. 6. (a) Pristine &#x2018;h, (b) broken  &#x2018;h&#x2019;, (c) </span></b></p>\n<p style=\"top:441.7pt;left:352.6pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">features matched to prototypes. </span></b></p>\n<p style=\"top:453.7pt;left:428.6pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\"> </span></b></p>\n<p style=\"top:465.0pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The breakthrough solution is the idea that the </span></p>\n<p style=\"top:476.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">features in the unknown need not be the same as the </span></p>\n<p style=\"top:488.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">features in the training data. During training, the </span></p>\n<p style=\"top:499.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">segments of a polygonal approximation [2] are used for </span></p>\n<p style=\"top:511.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">features, but in recognition, features of a small, fixed </span></p>\n<p style=\"top:522.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">length (in normalized units) are extracted from the </span></p>\n<p style=\"top:534.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">outline and matched many-to-one against the clustered </span></p>\n<p style=\"top:545.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">prototype features of the training data. In Fig. 6(c), the </span></p>\n<p style=\"top:557.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">short, thick lines are the features extracted from the </span></p>\n<p style=\"top:568.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">unknown, and the thin, longer lines are the clustered </span></p>\n<p style=\"top:579.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">segments of the polygonal approximation that are used </span></p>\n<p style=\"top:591.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">as prototypes. One prototype bridging the two pieces is </span></p>\n<p style=\"top:603.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">completely unmatched. Three features on one side and </span></p>\n<p style=\"top:614.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">two on the other are unmatched, but, apart from those, </span></p>\n<p style=\"top:626.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">every prototype and every feature is well matched. </span></p>\n<p style=\"top:637.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">This example shows that this process of small features </span></p>\n<p style=\"top:649.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">matching large prototypes is easily able to cope with </span></p>\n<p style=\"top:660.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">recognition of damaged images. Its main problem is </span></p>\n<p style=\"top:672.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">that the computational cost of computing the distance </span></p>\n<p style=\"top:683.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">between an unknown and a prototype is very high. </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:08:30.771826",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "<div id=\"page0\" style=\"width:612.0pt;height:792.0pt\">\n<p style=\"top:72.8pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The features extracted from the unknown are thus 3-</span></p>\n<p style=\"top:84.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">dimensional, (x, y position, angle), with typically 50-</span></p>\n<p style=\"top:95.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">100 features in a character, and the prototype features </span></p>\n<p style=\"top:107.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">are 4-dimensional (x, y, position, angle, length), with </span></p>\n<p style=\"top:118.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">typically 10-20 features in a prototype configuration. </span></p>\n<p style=\"top:130.4pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:142.1pt;left:72.0pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">5.2. Classification </span></b></p>\n<p style=\"top:154.4pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:165.9pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Classification proceeds as a two-step process. In the </span></p>\n<p style=\"top:177.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">first step, a </span><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">class pruner</span></i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> creates a shortlist of character </span></p>\n<p style=\"top:189.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">classes that the unknown might match. Each feature </span></p>\n<p style=\"top:200.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">fetches, from a coarsely quantized 3-dimensional look-</span></p>\n<p style=\"top:212.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">up table, a bit-vector of classes that it might match, and </span></p>\n<p style=\"top:223.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the bit-vectors are summed over all the features. The </span></p>\n<p style=\"top:235.1pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">classes with the highest counts (after correcting for </span></p>\n<p style=\"top:246.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">expected number of features) become the short-list for </span></p>\n<p style=\"top:257.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the next step. </span></p>\n<p style=\"top:269.4pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Each feature of the unknown looks up a bit vector </span></p>\n<p style=\"top:280.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">of prototypes of the given class that it might match, </span></p>\n<p style=\"top:292.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">and then the actual similarity between them is </span></p>\n<p style=\"top:303.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">computed. </span></p>\n<p style=\"top:303.9pt;left:126.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Each </span></p>\n<p style=\"top:303.9pt;left:157.9pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">prototype </span></p>\n<p style=\"top:303.9pt;left:207.9pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">character </span></p>\n<p style=\"top:303.9pt;left:256.6pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">class </span></p>\n<p style=\"top:303.9pt;left:288.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">is </span></p>\n<p style=\"top:315.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">represented by a logical sum-of-product expression </span></p>\n<p style=\"top:327.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">with each term called a </span><i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">configuration</span></i><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">, so the distance </span></p>\n<p style=\"top:338.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">calculation process keeps a record of the total </span></p>\n<p style=\"top:350.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">similarity </span></p>\n<p style=\"top:350.0pt;left:121.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">evidence </span></p>\n<p style=\"top:350.0pt;left:168.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">of </span></p>\n<p style=\"top:350.0pt;left:188.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">each </span></p>\n<p style=\"top:350.0pt;left:217.9pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">feature </span></p>\n<p style=\"top:350.0pt;left:257.1pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">in </span></p>\n<p style=\"top:350.0pt;left:276.3pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">each </span></p>\n<p style=\"top:361.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">configuration, as well as of each prototype. The best </span></p>\n<p style=\"top:373.1pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">combined distance, which is calculated from the </span></p>\n<p style=\"top:384.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">summed feature and prototype evidences, is the best </span></p>\n<p style=\"top:395.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">over all the stored configurations of the class. </span></p>\n<p style=\"top:407.4pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:419.3pt;left:72.0pt;line-height:11.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:11.0pt\">5.3. Training Data </span></b></p>\n<p style=\"top:431.6pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:443.1pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Since the classifier is able to recognize damaged </span></p>\n<p style=\"top:454.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">characters easily, the classifier was not trained on </span></p>\n<p style=\"top:466.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">damaged characters. In fact, the classifier was trained </span></p>\n<p style=\"top:477.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">on a mere 20 samples of 94 characters from 8 fonts in a </span></p>\n<p style=\"top:489.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">single size, but with 4 attributes (normal, bold, italic, </span></p>\n<p style=\"top:500.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">bold italic), making a total of 60160 training samples. </span></p>\n<p style=\"top:512.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">This is a significant contrast to other published </span></p>\n<p style=\"top:523.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">classifiers, such as the Calera classifier with more than </span></p>\n<p style=\"top:535.1pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">a million samples [9], and Baird&#x2019;s 100-font classifier </span></p>\n<p style=\"top:546.6pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">[10] with 1175000 training samples.  </span></p>\n<p style=\"top:558.1pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:570.2pt;left:72.0pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">6. Linguistic Analysis </span></b></p>\n<p style=\"top:583.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:594.8pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract </span></p>\n<p style=\"top:594.8pt;left:133.7pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">contains </span></p>\n<p style=\"top:594.8pt;left:178.3pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">relatively </span></p>\n<p style=\"top:594.8pt;left:227.3pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">little </span></p>\n<p style=\"top:594.8pt;left:257.3pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">linguistic </span></p>\n<p style=\"top:606.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">analysis. Whenever the word recognition module is </span></p>\n<p style=\"top:617.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">considering a new segmentation, the linguistic module </span></p>\n<p style=\"top:629.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">(mis-named the permuter) chooses the best available </span></p>\n<p style=\"top:640.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">word string in each of the following categories: Top </span></p>\n<p style=\"top:652.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">frequent word, Top dictionary word, Top numeric </span></p>\n<p style=\"top:663.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">word, Top UPPER case word, Top lower case word </span></p>\n<p style=\"top:675.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">(with optional initial upper), Top classifier choice </span></p>\n<p style=\"top:687.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">word. The final decision for a given segmentation is </span></p>\n<p style=\"top:72.8pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">simply the word with the lowest total distance rating, </span></p>\n<p style=\"top:84.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">where each of the above categories is multiplied by a </span></p>\n<p style=\"top:95.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">different constant. </span></p>\n<p style=\"top:107.4pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Words from different segmentations may have </span></p>\n<p style=\"top:118.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">different numbers of characters in them. It is hard to </span></p>\n<p style=\"top:130.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">compare these words directly, even where a classifier </span></p>\n<p style=\"top:141.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">claims to be producing probabilities, which Tesseract </span></p>\n<p style=\"top:153.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">does not. This problem is solved in Tesseract by </span></p>\n<p style=\"top:164.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">generating </span></p>\n<p style=\"top:164.7pt;left:372.7pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">two </span></p>\n<p style=\"top:164.7pt;left:400.1pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">numbers </span></p>\n<p style=\"top:164.7pt;left:447.6pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">for </span></p>\n<p style=\"top:164.7pt;left:472.1pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">each </span></p>\n<p style=\"top:164.7pt;left:503.3pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">character </span></p>\n<p style=\"top:176.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">classification. The first, called the confidence, is minus </span></p>\n<p style=\"top:187.8pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the normalized distance from the prototype. This </span></p>\n<p style=\"top:199.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">enables it to be a &#x201c;confidence&#x201d; in the sense that greater </span></p>\n<p style=\"top:210.8pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">numbers are better, but still a distance, as, the farther </span></p>\n<p style=\"top:222.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">from zero, the greater the distance. The second output, </span></p>\n<p style=\"top:233.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">called the rating, multiplies the normalized distance </span></p>\n<p style=\"top:245.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">from the prototype by the total outline length in the </span></p>\n<p style=\"top:256.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">unknown character. Ratings for characters within a </span></p>\n<p style=\"top:268.4pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">word can be summed meaningfully, since the total </span></p>\n<p style=\"top:279.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">outline length for all characters within a word is always </span></p>\n<p style=\"top:291.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the same.  </span></p>\n<p style=\"top:302.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:314.9pt;left:317.5pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">7. Adaptive Classifier </span></b></p>\n<p style=\"top:328.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:339.7pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">It has been suggested [11] and demonstrated [12] </span></p>\n<p style=\"top:351.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">that OCR engines can benefit from the use of an </span></p>\n<p style=\"top:362.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">adaptive classifier. Since the static classifier has to be </span></p>\n<p style=\"top:374.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">good at generalizing to any kind of font, its ability to </span></p>\n<p style=\"top:385.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">discriminate between different characters or between </span></p>\n<p style=\"top:397.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">characters and non-characters is weakened. A more </span></p>\n<p style=\"top:408.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">font-sensitive adaptive classifier that is trained by the </span></p>\n<p style=\"top:420.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">output of the static classifier is therefore commonly </span></p>\n<p style=\"top:431.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">[13] used to obtain greater discrimination within each </span></p>\n<p style=\"top:443.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">document, where the number of fonts is limited. </span></p>\n<p style=\"top:454.7pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract does not employ a template classifier, but </span></p>\n<p style=\"top:466.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">uses the same features and classifier as the static </span></p>\n<p style=\"top:477.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">classifier. The only significant difference between the </span></p>\n<p style=\"top:489.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">static classifier and the adaptive classifier, apart from </span></p>\n<p style=\"top:500.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">the training data, is that the adaptive classifier uses </span></p>\n<p style=\"top:512.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">isotropic baseline/x-height normalization, whereas the </span></p>\n<p style=\"top:523.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">static classifier normalizes characters by the centroid </span></p>\n<p style=\"top:535.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">(first moments) for position and second moments for </span></p>\n<p style=\"top:546.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">anisotropic size normalization. </span></p>\n<p style=\"top:558.1pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The baseline/x-height normalization makes it easier </span></p>\n<p style=\"top:569.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">to distinguish upper and lower case characters as well </span></p>\n<p style=\"top:581.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">as improving immunity to noise specks. The main </span></p>\n<p style=\"top:592.7pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">benefit of character moment normalization is removal </span></p>\n<p style=\"top:604.2pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">of font aspect ratio and some degree of font stroke </span></p>\n<p style=\"top:615.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">width. It also makes recognition of sub and </span></p>\n<p style=\"top:627.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">superscripts simpler, but requires an additional </span></p>\n<p style=\"top:638.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">classifier feature to distinguish some upper and lower </span></p>\n<p style=\"top:650.0pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">case characters. Fig. 7 shows an example of 3 letters in </span></p>\n<p style=\"top:661.5pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">baseline/x-height normalized form and moment </span></p>\n<p style=\"top:673.1pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">normalized form. </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:08:30.810946",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": "<div id=\"page0\" style=\"width:612.0pt;height:792.0pt\">\n<img style=\"position:absolute;transform:matrix(.3288889,0,-0,.3296,-206,28.960007)\" src=\"data:image/png;base64,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\nrkJggg==\">\n<p style=\"top:113.4pt;left:294.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:122.7pt;left:87.8pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">Fig. 7. Baseline and moment normalized </span></b></p>\n<p style=\"top:134.5pt;left:166.8pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">letters. </span></b></p>\n<p style=\"top:146.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:158.2pt;left:72.0pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">8. Results </span></b></p>\n<p style=\"top:171.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:182.7pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract was included in the 4</span><sup><span style=\"font-family:Times New Roman,serif;font-size:6.5pt\">th</span></sup><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> UNLV annual test </span></p>\n<p style=\"top:194.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">[1] of OCR accuracy, as &#x201c;HP Labs OCR,&#x201d; but the code </span></p>\n<p style=\"top:205.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">has changed a lot since then, including conversion to </span></p>\n<p style=\"top:217.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Unicode and retraining. Table 1 compares results from </span></p>\n<p style=\"top:228.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">a recent version of Tesseract (shown as 2.0) with the </span></p>\n<p style=\"top:240.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">original 1995 results (shown as HP). All four 300 DPI </span></p>\n<p style=\"top:251.9pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">binary test sets that were used in the 1995 test are </span></p>\n<p style=\"top:263.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">shown, along with the number of errors (Errs), the </span></p>\n<p style=\"top:274.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">percent error rate (%Err) and the percent change </span></p>\n<p style=\"top:286.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">relative to the 1995 results (%Chg) for both character </span></p>\n<p style=\"top:297.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">errors and non-stopword errors. [1] More up-to-date </span></p>\n<p style=\"top:309.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">results are at http://code.google.com/p/tesseract-ocr. </span></p>\n<p style=\"top:320.7pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:332.7pt;left:74.2pt;line-height:10.1pt\"><b><span style=\"font-family:Arial,serif;font-size:10.1pt\">Table 1. Results of Current and old Tesseract. </span></b></p>\n<p style=\"top:344.8pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:344.8pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:344.8pt;left:145.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Character </span></p>\n<p style=\"top:344.8pt;left:241.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Word </span></p>\n<p style=\"top:355.6pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Ver Set </span></p>\n<p style=\"top:355.6pt;left:121.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Errs </span></p>\n<p style=\"top:355.6pt;left:151.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">%Err %Chg Errs </span></p>\n<p style=\"top:355.6pt;left:241.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">%Err %Chg </span></p>\n<p style=\"top:366.4pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">HP </span></p>\n<p style=\"top:366.4pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">bus </span></p>\n<p style=\"top:366.4pt;left:127.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">5959 </span></p>\n<p style=\"top:366.4pt;left:156.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">1.86 </span></p>\n<p style=\"top:366.4pt;left:204.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:366.4pt;left:217.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">1293 </span></p>\n<p style=\"top:366.4pt;left:246.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">4.27</span></p>\n<p style=\"top:377.2pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.0 </span></p>\n<p style=\"top:377.2pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">bus </span></p>\n<p style=\"top:377.2pt;left:127.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">6449 </span></p>\n<p style=\"top:377.2pt;left:156.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.02 </span></p>\n<p style=\"top:377.2pt;left:187.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">8.22 </span></p>\n<p style=\"top:377.2pt;left:217.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">1295 </span></p>\n<p style=\"top:377.2pt;left:246.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">4.28</span></p>\n<p style=\"top:377.2pt;left:278.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">0.15</span></p>\n<p style=\"top:388.0pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">HP </span></p>\n<p style=\"top:388.0pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">doe </span></p>\n<p style=\"top:388.0pt;left:122.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">36349 </span></p>\n<p style=\"top:388.0pt;left:156.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.48 </span></p>\n<p style=\"top:388.0pt;left:204.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:388.0pt;left:217.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">7042 </span></p>\n<p style=\"top:388.0pt;left:246.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">5.13</span></p>\n<p style=\"top:398.8pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.0 </span></p>\n<p style=\"top:398.8pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">doe </span></p>\n<p style=\"top:398.8pt;left:122.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">29921 </span></p>\n<p style=\"top:398.8pt;left:156.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.04 -17.68 </span></p>\n<p style=\"top:398.8pt;left:217.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">6791 </span></p>\n<p style=\"top:398.8pt;left:246.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">4.95</span></p>\n<p style=\"top:398.8pt;left:275.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">-3.56</span></p>\n<p style=\"top:409.8pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">HP </span></p>\n<p style=\"top:409.8pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">mag </span></p>\n<p style=\"top:409.8pt;left:122.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">15043 </span></p>\n<p style=\"top:409.8pt;left:156.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.26 </span></p>\n<p style=\"top:409.8pt;left:204.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:409.8pt;left:217.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">3379 </span></p>\n<p style=\"top:409.8pt;left:246.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">5.01</span></p>\n<p style=\"top:420.6pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.0 </span></p>\n<p style=\"top:420.6pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">mag </span></p>\n<p style=\"top:420.6pt;left:122.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">14814 </span></p>\n<p style=\"top:420.6pt;left:156.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.22 </span></p>\n<p style=\"top:420.6pt;left:185.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">-1.52 </span></p>\n<p style=\"top:420.6pt;left:217.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">3133 </span></p>\n<p style=\"top:420.6pt;left:246.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">4.64</span></p>\n<p style=\"top:420.6pt;left:275.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">-7.28</span></p>\n<p style=\"top:431.4pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">HP </span></p>\n<p style=\"top:431.4pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">news </span></p>\n<p style=\"top:431.4pt;left:127.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">6432 </span></p>\n<p style=\"top:431.4pt;left:156.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">1.31 </span></p>\n<p style=\"top:431.4pt;left:204.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:431.4pt;left:217.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">1502 </span></p>\n<p style=\"top:431.4pt;left:246.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">3.06</span></p>\n<p style=\"top:442.2pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.0 </span></p>\n<p style=\"top:442.2pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">news </span></p>\n<p style=\"top:442.2pt;left:127.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">7935 </span></p>\n<p style=\"top:442.2pt;left:156.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">1.61 </span></p>\n<p style=\"top:442.2pt;left:183.6pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">23.36 </span></p>\n<p style=\"top:442.2pt;left:217.4pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">1284 </span></p>\n<p style=\"top:442.2pt;left:246.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.62</span></p>\n<p style=\"top:442.2pt;left:270.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">-14.51</span></p>\n<p style=\"top:453.0pt;left:72.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">2.0 </span></p>\n<p style=\"top:453.0pt;left:95.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">total </span></p>\n<p style=\"top:453.0pt;left:122.9pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">59119 </span></p>\n<p style=\"top:453.0pt;left:172.6pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:453.0pt;left:185.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">-7.31 12503 </span></p>\n<p style=\"top:453.0pt;left:275.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">-5.39</span></p>\n<p style=\"top:464.0pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:475.9pt;left:72.0pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">9. Conclusion and Further Work </span></b></p>\n<p style=\"top:489.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:500.7pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">After lying dormant for more than 10 years, </span></p>\n<p style=\"top:512.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Tesseract is now behind the leading commercial </span></p>\n<p style=\"top:523.8pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">engines in terms of its accuracy. Its key strength is </span></p>\n<p style=\"top:535.3pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">probably its unusual choice of features. Its key </span></p>\n<p style=\"top:546.6pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">weakness is probably its use of a polygonal </span></p>\n<p style=\"top:558.1pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">approximation as input to the classifier instead of the </span></p>\n<p style=\"top:569.6pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">raw outlines. </span></p>\n<p style=\"top:581.1pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">With internationalization done, accuracy could </span></p>\n<p style=\"top:592.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">probably be improved significantly with the judicious </span></p>\n<p style=\"top:604.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">addition of a Hidden-Markov-Model-based character </span></p>\n<p style=\"top:615.7pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">n-gram model, and possibly an improved chopper. </span></p>\n<p style=\"top:627.2pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:639.4pt;left:72.0pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">10. Acknowledgements </span></b></p>\n<p style=\"top:652.4pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:663.9pt;left:84.2pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">The author would like to thank John Burns and Tom </span></p>\n<p style=\"top:675.5pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Nartker for their efforts in making Tesseract open </span></p>\n<p style=\"top:687.0pt;left:72.0pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">source, the ISRI group at UNLV for sharing their tools </span></p>\n<p style=\"top:72.8pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">and data, as well as Luc Vincent, Igor Krivokon, Dar-</span></p>\n<p style=\"top:84.3pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">Shyang Lee, and Thomas Kielbus for their comments </span></p>\n<p style=\"top:95.9pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\">on the content of this paper. </span></p>\n<p style=\"top:107.4pt;left:329.8pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:119.5pt;left:317.5pt;line-height:12.0pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:12.0pt\">11. References </span></b></p>\n<p style=\"top:132.6pt;left:317.5pt;line-height:10.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:10.1pt\"> </span></p>\n<p style=\"top:144.1pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">The Fourth Annual </span></i></p>\n<p style=\"top:154.5pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Test of OCR Accuracy,</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Technical Report 95-03</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">, Information </span></p>\n<p style=\"top:164.8pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Science Research Institute, University of Nevada, Las Vegas, </span></p>\n<p style=\"top:175.1pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">July 1995. </span></p>\n<p style=\"top:185.7pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:196.0pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[2] R.W. Smith, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">The Extraction and Recognition of Text from </span></i></p>\n<p style=\"top:206.3pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Multimedia Document Images, </span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">PhD Thesis, University of </span></p>\n<p style=\"top:216.6pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Bristol, November 1987. </span></p>\n<p style=\"top:226.9pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:237.3pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[3] R. Smith, &#x201c;A Simple and Efficient Skew Detection </span></p>\n<p style=\"top:247.6pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Algorithm via Text Row Accumulation&#x201d;, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Proc. of the 3</span></i><sup><i><span style=\"font-family:Times New Roman,serif;font-size:6.0pt\">rd</span></i></sup><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> Int. </span></i></p>\n<p style=\"top:257.9pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Conf. on Document Analysis and Recognition</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> (Vol. 2), IEEE </span></p>\n<p style=\"top:268.5pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">1995, pp. 1145-1148. </span></p>\n<p style=\"top:278.8pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:289.1pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[4] P.J. Rousseeuw, A.M. Leroy, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Robust Regression and </span></i></p>\n<p style=\"top:299.4pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Outlier Detection</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">, Wiley-IEEE, 2003. </span></p>\n<p style=\"top:309.7pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:320.1pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[5] S.V. Rice, G. Nagy, T.A. Nartker, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Optical Character </span></i></p>\n<p style=\"top:330.4pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Recognition: An Illustrated Guide to the Frontier</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">, Kluwer </span></p>\n<p style=\"top:340.7pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Academic Publishers, USA 1999, pp. 57-60. </span></p>\n<p style=\"top:351.0pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:361.6pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[6] P.J. Schneider, &#x201c;An Algorithm for Automatically Fitting </span></p>\n<p style=\"top:371.9pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Digitized Curves&#x201d;, in A.S. Glassner, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Graphics Gems I</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">, </span></p>\n<p style=\"top:382.2pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Morgan Kaufmann, 1990, pp. 612-626. </span></p>\n<p style=\"top:392.5pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:402.9pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[7] R.J. Shillman, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Character Recognition Based on </span></i></p>\n<p style=\"top:413.2pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Phenomenological Attributes: Theory and Methods, </span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">PhD. </span></p>\n<p style=\"top:423.5pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Thesis</span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">,</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> Massachusetts Institute of Technology. 1974. </span></p>\n<p style=\"top:433.8pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:444.4pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, &#x201c;Empirical </span></p>\n<p style=\"top:454.7pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Tests for Feature Selection Based on a Pscychological </span></p>\n<p style=\"top:465.0pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Theory of Character Recognition&#x201d;, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Pattern Recognition</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span><b><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">8</span></b><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">(2),  </span></p>\n<p style=\"top:475.3pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Elsevier, New York, 1976. </span></p>\n<p style=\"top:485.7pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:496.0pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[9] M. Bokser, &#x201c;Omnidocument Technologies&#x201d;, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Proc. IEEE</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:506.3pt;left:317.5pt;line-height:9.1pt\"><b><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">80</span></b><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">(7), IEEE, USA, Jul 1992, pp. 1066-1078. </span></p>\n<p style=\"top:516.6pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:527.2pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[10] H.S. Baird, R. Fossey, &#x201c;A 100-Font Classifier&#x201d;, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Proc. of </span></i></p>\n<p style=\"top:537.5pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">the 1</span></i><sup><i><span style=\"font-family:Times New Roman,serif;font-size:6.0pt\">st</span></i></sup><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> Int. Conf. on Document Analysis and Recognition</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">, </span></p>\n<p style=\"top:547.8pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">IEEE, 1991, pp 332-340. </span></p>\n<p style=\"top:558.1pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:568.5pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[11] G. Nagy, &#x201c;At the frontiers of OCR&#x201d;, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Proc. IEEE</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span><b><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">80(</span></b><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">7</span><b><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">)</span></b><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">, </span></p>\n<p style=\"top:578.8pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">IEEE, USA, Jul 1992, pp 1093-1100. </span></p>\n<p style=\"top:589.1pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:599.4pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[12] G. Nagy, Y. Xu, &#x201c;Automatic Prototype Extraction for </span></p>\n<p style=\"top:610.0pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Adaptive OCR&#x201d;, </span><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Proc. of the 4</span></i><sup><i><span style=\"font-family:Times New Roman,serif;font-size:6.0pt\">th</span></i></sup><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> Int. Conf. on Document </span></i></p>\n<p style=\"top:620.3pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Analysis and Recognition</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">, IEEE, Aug 1997, pp 278-282. </span></p>\n<p style=\"top:630.6pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> </span></p>\n<p style=\"top:640.9pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">[13] I. Marosi, &#x201c;Industrial OCR approaches: architecture, </span></p>\n<p style=\"top:651.3pt;left:317.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">algorithms </span></p>\n<p style=\"top:651.3pt;left:369.1pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">and </span></p>\n<p style=\"top:651.3pt;left:395.0pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">adaptation </span></p>\n<p style=\"top:651.3pt;left:445.5pt;line-height:9.1pt\"><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">techniques&#x201d;, </span></p>\n<p style=\"top:651.3pt;left:503.3pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Document </span></i></p>\n<p style=\"top:661.6pt;left:317.5pt;line-height:9.1pt\"><i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\">Recognition and Retrieval XIV,</span></i><span style=\"font-family:Times New Roman,serif;font-size:9.1pt\"> SPIE Jan 2007,  6500-01. </span></p>\n</div>\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:11:26.391489",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:14:25.329217",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "[(70.8239974975586, 72.95999145507812, 79.31985473632812, 83.99999237060547, 'R \\n', 0, 0), (70.8239974975586, 95.54000854492188, 73.31985473632812, 106.58000946044922, ' \\n', 1, 0), (70.8239974975586, 117.98001098632812, 73.31985473632812, 129.02000427246094, ' \\n', 2, 0), (70.8239974975586, 140.54000854492188, 73.31985473632812, 151.5800018310547, ' \\n', 3, 0), (70.8239974975586, 162.98001098632812, 73.31985473632812, 174.02000427246094, ' \\n', 4, 0), (70.8239974975586, 185.54000854492188, 73.31985473632812, 196.5800018310547, ' \\n', 5, 0), (70.8239974975586, 207.98001098632812, 73.31985473632812, 219.02000427246094, ' \\n', 6, 0), (70.8239974975586, 230.42001342773438, 476.9558410644531, 241.4600067138672, ' \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSdf \\n', 7, 0), (70.8239974975586, 252.98001098632812, 73.31985473632812, 264.02001953125, ' \\n', 8, 0), (70.8239974975586, 275.4499816894531, 73.31985473632812, 286.489990234375, ' \\n', 9, 0), (70.8239974975586, 298.0099792480469, 96.35985565185547, 309.04998779296875, 'Pzicn \\n', 10, 0), (70.8239974975586, 320.4499816894531, 73.31985473632812, 331.489990234375, ' \\n', 11, 0), (70.8239974975586, 342.8899841308594, 73.31985473632812, 353.92999267578125, ' \\n', 12, 0), (70.8239974975586, 365.4499816894531, 242.66586303710938, 376.489990234375, ' \\n \\n \\n \\nudchd \\n', 13, 0)]"
        },
        {
            "date": "2023-01-06",
            "time": "14:17:19.338796",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:17:47.842171",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:18:07.398700",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:18:07.417701",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:18:07.433033",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:18:07.449023",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:18:07.465075",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:19:34.924810",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:19:34.944804",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:19:34.964366",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:19:34.983813",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:19:35.000790",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "14:21:06.086889",
            "file": "news_1.webp_1673011264943.webp",
            "content": "\u201cA city centre theatre would\nnot just be for Exeter residents,\nbecause cities which have\ntheatres now attract people\nfrom as much as 300 miles away.\nWith the hotels and restaurants:\nExeter has now, together with a\n\u201cflagship\u201d store such as John\nLewis and others, packages\ncould be put together te create\nmuch extra revenue for city\ncentre businesses\n"
        },
        {
            "date": "2023-01-06",
            "time": "14:21:42.065814",
            "file": "web_app/static/sp2_1673011302040.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "14:22:51.976783",
            "file": "web_app/static/news2_1673011371949.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "14:23:08.120185",
            "file": "web_app/static/news2_1673011388083.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "14:23:32.306153",
            "file": "web_app/static/sp1_1673011412281.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "14:23:45.560581",
            "file": "web_app/static/sample_5_1673011425526.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "14:24:00.034736",
            "file": "web_app/static/mupdf_library_dependencies_1673011440005.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "14:24:12.624415",
            "file": "web_app/static/mupdf_library_dependencies_1673011452592.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "16:26:03.929221",
            "file": "hdig_6_1673018763402.jpg",
            "content": "BOX 0 => 7, BOX 1 => 2"
        },
        {
            "date": "2023-01-06",
            "time": "16:26:47.513225",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:38:16.933621",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:38:16.949218",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:38:16.964844",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:38:16.981980",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:38:16.997617",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:41:40.498423",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:41:40.514061",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:41:40.529686",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:41:40.545310",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:41:40.560937",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:42:47.965799",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:42:47.986975",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:42:48.002608",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:42:48.018233",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:42:48.048137",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:43:38.331227",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:43:38.357239",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:43:38.368744",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:43:38.389736",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "16:43:38.405365",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:02:02.932172",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:02:42.790363",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:03:01.058596",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:03:01.074175",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:03:01.089797",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:03:01.105422",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:03:01.136672",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:05:55.922890",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:05:55.938573",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:05:55.954198",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:05:55.969778",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:05:55.985396",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:06:28.567682",
            "file": "web_app/static/sample_2_1673021188420.png p.0",
            "content": ""
        },
        {
            "date": "2023-01-06",
            "time": "17:06:49.756241",
            "file": "hdig_2_1673021208955.png",
            "content": "BOX 0 => 0, BOX 1 => 7, BOX 2 => 8, BOX 3 => 2, BOX 4 => 0, BOX 5 => 3, BOX 6 => 8"
        },
        {
            "date": "2023-01-06",
            "time": "17:08:00.590951",
            "file": "hdig_6_1673021280046.jpg",
            "content": "BOX 0 => 6, BOX 1 => 7"
        },
        {
            "date": "2023-01-06",
            "time": "17:08:15.094362",
            "file": "web_app/static/sample_0.pdf p.0",
            "content": "Hello World \nHello World1 \n \nHello World2 \n \n \nHello World3 \n \n \nHello World4 \nHello World5 \nHello World6 \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:08:26.586578",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.0",
            "content": "An Overview of the Tesseract OCR Engine \n \n \nRay Smith  \nGoogle Inc. \ntheraysmith@gmail.com \n \nAbstract \n \nThe Tesseract OCR engine, as was the HP Research \nPrototype in the UNLV Fourth Annual Test of OCR \nAccuracy[1], is described in a comprehensive \noverview. Emphasis is placed on aspects that are novel \nor at least unusual in an OCR engine, including in \nparticular the line finding, features/classification \nmethods, and the adaptive classifier. \n  \n \n1. Introduction \u2013 Motivation and History \n \nTesseract is an open-source OCR engine that was \ndeveloped at HP between 1984 and 1994. Like a super-\nnova, it appeared from nowhere for the 1995 UNLV \nAnnual Test of OCR Accuracy [1], shone brightly with \nits results, and then vanished back under the same \ncloak of secrecy under which it had been developed. \nNow for the first time, details of the architecture and \nalgorithms can be revealed. \nTesseract began as a PhD research project [2] in HP \nLabs, Bristol, and gained momentum as a possible \nsoftware and/or hardware add-on for HP\u2019s line of \nflatbed scanners. Motivation was provided by the fact \nthat the commercial OCR engines of the day were in \ntheir infancy, and failed miserably on anything but the \nbest quality print. \nAfter a joint project between HP Labs Bristol, and \nHP\u2019s scanner division in Colorado, Tesseract had a \nsignificant lead in accuracy over the commercial \nengines, but did not become a product. The next stage \nof its development was back in HP Labs Bristol as an \ninvestigation \nof \nOCR \nfor \ncompression. \nWork \nconcentrated more on improving rejection efficiency \nthan on base-level accuracy. At the end of this project, \nat the end of 1994, development ceased entirely. The \nengine was sent to UNLV for the 1995 Annual Test of \nOCR Accuracy[1], where it proved its worth against \nthe commercial engines of the time. In late 2005, HP \nreleased Tesseract for open source. It is now available \nat http://code.google.com/p/tesseract-ocr. \n \n2. Architecture \n \nSince HP had independently-developed page layout \nanalysis technology that was used in products, (and \ntherefore not released for open-source) Tesseract never \nneeded its own page layout analysis. Tesseract \ntherefore assumes that its input is a binary image with \noptional polygonal text regions defined. \nProcessing follows a traditional step-by-step \npipeline, but some of the stages were unusual in their \nday, and possibly remain so even now. The first step is \na connected component analysis in which outlines of \nthe components are stored. This was a computationally \nexpensive design decision at the time, but had a \nsignificant advantage: by inspection of the nesting of \noutlines, and the number of child and grandchild \noutlines, it is simple to detect inverse text and \nrecognize it as easily as black-on-white text. Tesseract \nwas probably the first OCR engine able to handle \nwhite-on-black text so trivially. At this stage, outlines \nare gathered together, purely by nesting, into Blobs. \nBlobs are organized into text lines, and the lines and \nregions are analyzed for fixed pitch or proportional \ntext. Text lines are broken into words differently \naccording to the kind of character spacing. Fixed pitch \ntext is chopped immediately by character cells. \nProportional text is broken into words using definite \nspaces and fuzzy spaces. \nRecognition then proceeds as a two-pass process. In \nthe first pass, an attempt is made to recognize each \nword in turn. Each word that is satisfactory is passed to \nan adaptive classifier as training data. The adaptive \nclassifier then gets a chance to more accurately \nrecognize text lower down the page. \nSince the adaptive classifier may have learned \nsomething useful too late to make a contribution near \nthe top of the page, a second pass is run over the page, \nin which words that were not recognized well enough \nare recognized again. \nA final phase resolves fuzzy spaces, and checks \nalternative hypotheses for the x-height to locate small-\ncap text. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:08:26.602242",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.1",
            "content": "3. Line and Word Finding \n \n3.1. Line Finding \n \nThe line finding algorithm is one of the few parts of \nTesseract that has previously been published [3]. The \nline finding algorithm is designed so that a skewed \npage can be recognized without having to de-skew, \nthus saving loss of image quality. The key parts of the \nprocess are blob filtering and line construction. \nAssuming that page layout analysis has already \nprovided text regions of a roughly uniform text size, a \nsimple percentile height filter removes drop-caps and \nvertically touching characters. The median height \napproximates the text size in the region, so it is safe to \nfilter out blobs that are smaller than some fraction of \nthe median height, being most likely punctuation, \ndiacritical marks and noise. \nThe filtered blobs are more likely to fit a model of \nnon-overlapping, parallel, but sloping lines. Sorting \nand processing the blobs by x-coordinate makes it \npossible to assign blobs to a unique text line, while \ntracking the slope across the page, with greatly reduced \ndanger of assigning to an incorrect text line in the \npresence of skew. Once the filtered blobs have been \nassigned to lines, a least median of squares fit [4] is \nused to estimate the baselines, and the filtered-out \nblobs are fitted back into the appropriate lines. \nThe final step of the line creation process merges \nblobs that overlap by at least half horizontally, putting \ndiacritical marks together with the correct base and \ncorrectly associating parts of some broken characters. \n \n3.2. Baseline Fitting \n \nOnce the text lines have been found, the baselines \nare fitted more precisely using a quadratic spline. This \nwas another first for an OCR system, and enabled \nTesseract to handle pages with curved baselines [5], \nwhich are a common artifact in scanning, and not just \nat book bindings. \nThe baselines are fitted by partitioning the blobs \ninto groups with a reasonably continuous displacement \nfor the original straight baseline. A quadratic spline is \nfitted to the most populous partition, (assumed to be \nthe baseline) by a least squares fit. The quadratic spline \nhas the advantage that this calculation is reasonably \nstable, but the disadvantage that discontinuities can \narise when multiple spline segments are required. A \nmore traditional cubic spline [6] might work better. \n \nFig. 1. An example of a curved fitted baseline. \nFig.1 shows an example of a line of text with a \nfitted baseline, descender line, meanline and ascender \nline. All these lines are \u201cparallel\u201d (the y separation is a \nconstant over the entire length) and slightly curved. \nThe ascender line is cyan (prints as light gray) and the \nblack line above it is actually straight. Close inspection \nshows that the cyan/gray line is curved relative to the \nstraight black line above it. \n \n3.3. Fixed Pitch Detection and Chopping \n \nTesseract tests the text lines to determine whether \nthey are fixed pitch. Where it finds fixed pitch text, \nTesseract chops the words into characters using the \npitch, and disables the chopper and associator on these \nwords for the word recognition step. Fig. 2 shows a \ntypical example of a fixed-pitch word. \n \nFig. 2. A fixed-pitch chopped word. \n \n3.4. Proportional Word Finding \n \nNon-fixed-pitch or proportional text spacing is a \nhighly non-trivial task. Fig. 3 illustrates some typical \nproblems. The gap between the tens and units of \n\u201811.9%\u2019 is a similar size to the general space, and is \ncertainly larger than the kerned space between \u2018erated\u2019 \nand \u2018junk\u2019. There is no horizontal gap at all between \nthe bounding boxes of \u2018of\u2019 and \u2018financial\u2019. Tesseract \nsolves most of these problems by measuring gaps in a \nlimited vertical range between the baseline and mean \nline. Spaces that are close to the threshold at this stage \nare made fuzzy, so that a final decision can be made \nafter word recognition. \n \n \nFig. 3. Some difficult word spacing. \n \n4. Word Recognition \n \nPart of the recognition process for any character \nrecognition engine is to identify how a word should be \nsegmented into characters. The initial segmentation \noutput from line finding is classified first. The rest of \nthe word recognition step applies only to non-fixed-\npitch text.  \n \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:08:26.617885",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.2",
            "content": "4.1 Chopping Joined Characters \n \nWhile the result from a word (see section 6) is \nunsatisfactory, Tesseract attempts to improve the result \nby chopping the blob with worst confidence from the \ncharacter classifier. Candidate chop points are found \nfrom concave vertices of a polygonal approximation \n[2] of the outline, and may have either another concave \nvertex opposite, or a line segment. It may take up to 3 \npairs of chop points to successfully separate joined \ncharacters from the ASCII set. \n \nFig. 4. Candidate chop points and chop. \n \nFig. 4 shows a set of candidate chop points with \narrows and the selected chop as a line across the \noutline where the \u2018r\u2019 touches the \u2018m\u2019. \nChops are executed in priority order. Any chop that \nfails to improve the confidence of the result is undone, \nbut not completely discarded so that the chop can be \nre-used later by the associator if needed. \n \n4.2. Associating Broken Characters \n \nWhen the potential chops have been exhausted, if \nthe word is still not good enough, it is given to the \nassociator. The associator makes an A* (best first) \nsearch of the segmentation graph of possible \ncombinations of the maximally chopped blobs into \ncandidate characters. It does this without actually \nbuilding the segmentation graph, but instead maintains \na hash table of visited states. The A* search proceeds \nby pulling candidate new states from a priority queue \nand evaluating them by classifying unclassified \ncombinations of fragments. \nIt may be argued that this fully-chop-then-associate \napproach is at best inefficient, at worst liable to miss \nimportant chops, and that may well be the case. The \nadvantage is that the chop-then-associate scheme \nsimplifies the data structures that would be required to \nmaintain the full segmentation graph. \n \nFig. 5. An easily recognized word. \nWhen the A* segmentation search was first \nimplemented in about 1989, Tesseract\u2019s accuracy on \nbroken characters was well ahead of the commercial \nengines of the day. Fig. 5 is a typical example. An \nessential part of that success was the character \nclassifier that could easily recognize broken characters. \n \n5. Static Character Classifier \n \n5.1. Features \n \nAn early version of Tesseract used topological \nfeatures developed from the work of Shillman et. al. \n[7-8] Though nicely independent of font and size, these \nfeatures are not robust to the problems found in real-\nlife images, as Bokser [9] describes. An intermediate \nidea involved the use of segments of the polygonal \napproximation as features, but this approach is also not \nrobust to damaged characters. For example, in Fig. \n6(a), the right side of the shaft is in two main pieces, \nbut in Fig. 6(b) there is just a single piece. \n \nFig. 6. (a) Pristine \u2018h, (b) broken  \u2018h\u2019, (c) \nfeatures matched to prototypes. \n \nThe breakthrough solution is the idea that the \nfeatures in the unknown need not be the same as the \nfeatures in the training data. During training, the \nsegments of a polygonal approximation [2] are used for \nfeatures, but in recognition, features of a small, fixed \nlength (in normalized units) are extracted from the \noutline and matched many-to-one against the clustered \nprototype features of the training data. In Fig. 6(c), the \nshort, thick lines are the features extracted from the \nunknown, and the thin, longer lines are the clustered \nsegments of the polygonal approximation that are used \nas prototypes. One prototype bridging the two pieces is \ncompletely unmatched. Three features on one side and \ntwo on the other are unmatched, but, apart from those, \nevery prototype and every feature is well matched. \nThis example shows that this process of small features \nmatching large prototypes is easily able to cope with \nrecognition of damaged images. Its main problem is \nthat the computational cost of computing the distance \nbetween an unknown and a prototype is very high. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:08:26.633510",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.3",
            "content": "The features extracted from the unknown are thus 3-\ndimensional, (x, y position, angle), with typically 50-\n100 features in a character, and the prototype features \nare 4-dimensional (x, y, position, angle, length), with \ntypically 10-20 features in a prototype configuration. \n \n5.2. Classification \n \nClassification proceeds as a two-step process. In the \nfirst step, a class pruner creates a shortlist of character \nclasses that the unknown might match. Each feature \nfetches, from a coarsely quantized 3-dimensional look-\nup table, a bit-vector of classes that it might match, and \nthe bit-vectors are summed over all the features. The \nclasses with the highest counts (after correcting for \nexpected number of features) become the short-list for \nthe next step. \nEach feature of the unknown looks up a bit vector \nof prototypes of the given class that it might match, \nand then the actual similarity between them is \ncomputed. \nEach \nprototype \ncharacter \nclass \nis \nrepresented by a logical sum-of-product expression \nwith each term called a configuration, so the distance \ncalculation process keeps a record of the total \nsimilarity \nevidence \nof \neach \nfeature \nin \neach \nconfiguration, as well as of each prototype. The best \ncombined distance, which is calculated from the \nsummed feature and prototype evidences, is the best \nover all the stored configurations of the class. \n \n5.3. Training Data \n \nSince the classifier is able to recognize damaged \ncharacters easily, the classifier was not trained on \ndamaged characters. In fact, the classifier was trained \non a mere 20 samples of 94 characters from 8 fonts in a \nsingle size, but with 4 attributes (normal, bold, italic, \nbold italic), making a total of 60160 training samples. \nThis is a significant contrast to other published \nclassifiers, such as the Calera classifier with more than \na million samples [9], and Baird\u2019s 100-font classifier \n[10] with 1175000 training samples.  \n \n6. Linguistic Analysis \n \nTesseract \ncontains \nrelatively \nlittle \nlinguistic \nanalysis. Whenever the word recognition module is \nconsidering a new segmentation, the linguistic module \n(mis-named the permuter) chooses the best available \nword string in each of the following categories: Top \nfrequent word, Top dictionary word, Top numeric \nword, Top UPPER case word, Top lower case word \n(with optional initial upper), Top classifier choice \nword. The final decision for a given segmentation is \nsimply the word with the lowest total distance rating, \nwhere each of the above categories is multiplied by a \ndifferent constant. \nWords from different segmentations may have \ndifferent numbers of characters in them. It is hard to \ncompare these words directly, even where a classifier \nclaims to be producing probabilities, which Tesseract \ndoes not. This problem is solved in Tesseract by \ngenerating \ntwo \nnumbers \nfor \neach \ncharacter \nclassification. The first, called the confidence, is minus \nthe normalized distance from the prototype. This \nenables it to be a \u201cconfidence\u201d in the sense that greater \nnumbers are better, but still a distance, as, the farther \nfrom zero, the greater the distance. The second output, \ncalled the rating, multiplies the normalized distance \nfrom the prototype by the total outline length in the \nunknown character. Ratings for characters within a \nword can be summed meaningfully, since the total \noutline length for all characters within a word is always \nthe same.  \n \n7. Adaptive Classifier \n \nIt has been suggested [11] and demonstrated [12] \nthat OCR engines can benefit from the use of an \nadaptive classifier. Since the static classifier has to be \ngood at generalizing to any kind of font, its ability to \ndiscriminate between different characters or between \ncharacters and non-characters is weakened. A more \nfont-sensitive adaptive classifier that is trained by the \noutput of the static classifier is therefore commonly \n[13] used to obtain greater discrimination within each \ndocument, where the number of fonts is limited. \nTesseract does not employ a template classifier, but \nuses the same features and classifier as the static \nclassifier. The only significant difference between the \nstatic classifier and the adaptive classifier, apart from \nthe training data, is that the adaptive classifier uses \nisotropic baseline/x-height normalization, whereas the \nstatic classifier normalizes characters by the centroid \n(first moments) for position and second moments for \nanisotropic size normalization. \nThe baseline/x-height normalization makes it easier \nto distinguish upper and lower case characters as well \nas improving immunity to noise specks. The main \nbenefit of character moment normalization is removal \nof font aspect ratio and some degree of font stroke \nwidth. It also makes recognition of sub and \nsuperscripts simpler, but requires an additional \nclassifier feature to distinguish some upper and lower \ncase characters. Fig. 7 shows an example of 3 letters in \nbaseline/x-height normalized form and moment \nnormalized form. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:08:26.664759",
            "file": "web_app/static/tesseract_paper_ray_smith.pdf p.4",
            "content": " \nFig. 7. Baseline and moment normalized \nletters. \n \n8. Results \n \nTesseract was included in the 4th UNLV annual test \n[1] of OCR accuracy, as \u201cHP Labs OCR,\u201d but the code \nhas changed a lot since then, including conversion to \nUnicode and retraining. Table 1 compares results from \na recent version of Tesseract (shown as 2.0) with the \noriginal 1995 results (shown as HP). All four 300 DPI \nbinary test sets that were used in the 1995 test are \nshown, along with the number of errors (Errs), the \npercent error rate (%Err) and the percent change \nrelative to the 1995 results (%Chg) for both character \nerrors and non-stopword errors. [1] More up-to-date \nresults are at http://code.google.com/p/tesseract-ocr. \n \nTable 1. Results of Current and old Tesseract. \n \n \nCharacter \nWord \nVer Set \nErrs \n%Err %Chg Errs \n%Err %Chg \nHP \nbus \n5959 \n1.86 \n \n1293 \n4.27\n2.0 \nbus \n6449 \n2.02 \n8.22 \n1295 \n4.28\n0.15\nHP \ndoe \n36349 \n2.48 \n \n7042 \n5.13\n2.0 \ndoe \n29921 \n2.04 -17.68 \n6791 \n4.95\n-3.56\nHP \nmag \n15043 \n2.26 \n \n3379 \n5.01\n2.0 \nmag \n14814 \n2.22 \n-1.52 \n3133 \n4.64\n-7.28\nHP \nnews \n6432 \n1.31 \n \n1502 \n3.06\n2.0 \nnews \n7935 \n1.61 \n23.36 \n1284 \n2.62\n-14.51\n2.0 \ntotal \n59119 \n \n-7.31 12503 \n-5.39\n \n9. Conclusion and Further Work \n \nAfter lying dormant for more than 10 years, \nTesseract is now behind the leading commercial \nengines in terms of its accuracy. Its key strength is \nprobably its unusual choice of features. Its key \nweakness is probably its use of a polygonal \napproximation as input to the classifier instead of the \nraw outlines. \nWith internationalization done, accuracy could \nprobably be improved significantly with the judicious \naddition of a Hidden-Markov-Model-based character \nn-gram model, and possibly an improved chopper. \n \n10. Acknowledgements \n \nThe author would like to thank John Burns and Tom \nNartker for their efforts in making Tesseract open \nsource, the ISRI group at UNLV for sharing their tools \nand data, as well as Luc Vincent, Igor Krivokon, Dar-\nShyang Lee, and Thomas Kielbus for their comments \non the content of this paper. \n \n11. References \n \n[1] S.V. Rice, F.R. Jenkins, T.A. Nartker, The Fourth Annual \nTest of OCR Accuracy, Technical Report 95-03, Information \nScience Research Institute, University of Nevada, Las Vegas, \nJuly 1995. \n \n[2] R.W. Smith, The Extraction and Recognition of Text from \nMultimedia Document Images, PhD Thesis, University of \nBristol, November 1987. \n \n[3] R. Smith, \u201cA Simple and Efficient Skew Detection \nAlgorithm via Text Row Accumulation\u201d, Proc. of the 3rd Int. \nConf. on Document Analysis and Recognition (Vol. 2), IEEE \n1995, pp. 1145-1148. \n \n[4] P.J. Rousseeuw, A.M. Leroy, Robust Regression and \nOutlier Detection, Wiley-IEEE, 2003. \n \n[5] S.V. Rice, G. Nagy, T.A. Nartker, Optical Character \nRecognition: An Illustrated Guide to the Frontier, Kluwer \nAcademic Publishers, USA 1999, pp. 57-60. \n \n[6] P.J. Schneider, \u201cAn Algorithm for Automatically Fitting \nDigitized Curves\u201d, in A.S. Glassner, Graphics Gems I, \nMorgan Kaufmann, 1990, pp. 612-626. \n \n[7] R.J. Shillman, Character Recognition Based on \nPhenomenological Attributes: Theory and Methods, PhD. \nThesis, Massachusetts Institute of Technology. 1974. \n \n[8] B.A. Blesser, T.T. Kuklinski, R.J. Shillman, \u201cEmpirical \nTests for Feature Selection Based on a Pscychological \nTheory of Character Recognition\u201d, Pattern Recognition 8(2),  \nElsevier, New York, 1976. \n \n[9] M. Bokser, \u201cOmnidocument Technologies\u201d, Proc. IEEE \n80(7), IEEE, USA, Jul 1992, pp. 1066-1078. \n \n[10] H.S. Baird, R. Fossey, \u201cA 100-Font Classifier\u201d, Proc. of \nthe 1st Int. Conf. on Document Analysis and Recognition, \nIEEE, 1991, pp 332-340. \n \n[11] G. Nagy, \u201cAt the frontiers of OCR\u201d, Proc. IEEE 80(7), \nIEEE, USA, Jul 1992, pp 1093-1100. \n \n[12] G. Nagy, Y. Xu, \u201cAutomatic Prototype Extraction for \nAdaptive OCR\u201d, Proc. of the 4th Int. Conf. on Document \nAnalysis and Recognition, IEEE, Aug 1997, pp 278-282. \n \n[13] I. Marosi, \u201cIndustrial OCR approaches: architecture, \nalgorithms \nand \nadaptation \ntechniques\u201d, \nDocument \nRecognition and Retrieval XIV, SPIE Jan 2007,  6500-01. \n"
        },
        {
            "date": "2023-01-06",
            "time": "17:10:02.833661",
            "file": "hdig_1_1673021402269.jpg",
            "content": "BOX 0 => 3, BOX 1 => 4, BOX 2 => 5"
        },
        {
            "date": "2023-01-06",
            "time": "17:11:32.653120",
            "file": "hdig_1_1673021492361.jpg",
            "content": "BOX 0 => 0, BOX 1 => 0"
        },
        {
            "date": "2023-01-06",
            "time": "17:13:56.795513",
            "file": "hdig_12_1673021636320.jpg",
            "content": "BOX 0 => 3"
        },
        {
            "date": "2023-01-06",
            "time": "17:16:00.377801",
            "file": "hdig_13_1673021759900.jpg",
            "content": "BOX 0 => 4"
        },
        {
            "date": "2023-01-06",
            "time": "17:17:16.408651",
            "file": "hdig_2_1673021835952.png",
            "content": "BOX 0 => 7"
        },
        {
            "date": "2023-01-06",
            "time": "17:17:52.370673",
            "file": "hdig_12_1673021871750.jpg",
            "content": "BOX 0 => 7, BOX 1 => 3, BOX 2 => 7"
        },
        {
            "date": "2023-01-06",
            "time": "17:18:33.108225",
            "file": "hdig_13_1673021912498.jpg",
            "content": "BOX 0 => 3, BOX 1 => 5, BOX 2 => 4"
        },
        {
            "date": "2023-01-06",
            "time": "17:18:48.335807",
            "file": "web_app/static/lone_letter.pdf p.0",
            "content": "R \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSdf \n \n \nPzicn \n \n \n \n \n \n \nudchd \n"
        }
    ]
}